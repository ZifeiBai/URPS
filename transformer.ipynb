{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# 1️⃣ Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2EettNg4TW5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738891299266,"user_tz":300,"elapsed":645,"user":{"displayName":"Zifei Bai","userId":"12413018286570323363"}},"outputId":"1e0e0029-44a5-453a-87e6-d8412dc4d40b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4djU5O8-in9","executionInfo":{"status":"ok","timestamp":1738891015848,"user_tz":300,"elapsed":143,"user":{"displayName":"Zifei Bai","userId":"12413018286570323363"}},"outputId":"50f1bcc5-5ad3-4835-f710-7de88864049d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WmNzSf047AQ"},"outputs":[],"source":["import math\n","import inspect\n","from dataclasses import dataclass\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"]},{"cell_type":"code","source":["vocab = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '+', '&', '*']\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","padding_token_index = 13\n","end_token_index = 12"],"metadata":{"id":"nBnXU-eyOwC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a mapping from chars to ints\n","stoi = {ch:i for i, ch in enumerate(vocab)}\n","itos = {i:ch for i, ch in enumerate(vocab)}\n","encode = lambda s:[stoi[c] for c in s] # encoder: take a string, output a list of ints\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of ints, output a string\n","\n","print(encode(\"1+2=3&\"))\n","print(decode(encode(\"1+2=3&\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e4EbjUWPBjj","executionInfo":{"status":"ok","timestamp":1738871129020,"user_tz":300,"elapsed":1,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"a1fc7335-7d49-4d1b-d474-aa5382ff06bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 11, 2, 10, 3, 12]\n","1+2=3&\n"]}]},{"cell_type":"code","source":["# train test split\n","train_set_1 = np.random.choice(np.arange(10), 8, replace=False)\n","train_set_2 = np.random.choice(np.arange(10, 100), 72, replace=False)\n","train_set_3 = np.random.choice(np.arange(100, 1000), 720, replace=False)\n","test_1 = np.setdiff1d(np.arange(10), train_set_1)\n","test_2 = np.setdiff1d(np.arange(10, 100), train_set_2)\n","test_3 = np.setdiff1d(np.arange(100, 1000), train_set_3)\n","test_12 = np.concatenate([test_1, test_2])\n","test = np.concatenate([test_1, test_2, test_3])\n","print(np.sort(train_set_1))\n","print(np.sort(train_set_2))\n","print(np.sort(test_1))\n","print(np.sort(test_2))\n","print(np.sort(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_juHaFr4xuH9","executionInfo":{"status":"ok","timestamp":1738871130514,"user_tz":300,"elapsed":109,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"0e072dc5-78df-403f-87a7-47853d7ec3cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 3 4 5 6 7 8 9]\n","[10 11 12 13 15 16 17 18 19 20 22 23 24 25 27 30 31 32 34 35 36 37 38 39\n"," 41 42 43 44 47 48 50 52 53 54 55 56 58 59 60 61 62 63 64 65 66 68 69 70\n"," 71 72 73 74 75 77 79 80 81 82 83 85 86 88 90 91 92 93 94 95 96 97 98 99]\n","[1 2]\n","[14 21 26 28 29 33 40 45 46 49 51 57 67 76 78 84 87 89]\n","[  1   2  14  21  26  28  29  33  40  45  46  49  51  57  67  76  78  84\n","  87  89 108 109 113 116 122 128 131 134 136 137 142 144 146 148 157 163\n"," 169 173 180 181 190 195 197 210 212 214 224 226 228 231 232 237 242 244\n"," 259 261 266 275 277 283 284 288 289 294 305 315 317 328 331 334 337 339\n"," 341 353 360 364 373 374 390 407 427 438 447 448 452 455 466 467 490 500\n"," 502 503 504 505 509 511 519 529 536 538 544 550 551 555 556 558 566 573\n"," 575 579 586 590 591 598 600 601 602 604 605 609 614 619 624 625 631 632\n"," 635 636 655 663 670 671 674 680 681 682 684 690 694 700 706 709 738 746\n"," 752 759 761 764 767 769 773 777 783 787 790 792 794 797 799 802 803 812\n"," 813 822 824 826 834 837 840 842 852 856 858 865 867 870 871 880 881 888\n"," 889 891 901 905 909 912 919 931 940 944 962 967 973 976 989 991 992 994\n"," 996 999]\n"]}]},{"cell_type":"code","source":["def get_batch(phase=None, batch_size=32, block_size=15, mode='train', train_set_1=train_set_1, train_set_2=train_set_2, train_set_3=train_set_3, test=test):\n","\n","    def sample_from_arrays(one_digit_array, two_digit_array, three_digit_array,\n","                       phase):\n","      # stratified sampling\n","        total_num_in_set = 1000\n","        if phase == 1:\n","          sampled_one = np.random.choice(one_digit_array, int(total_num_in_set*1), replace=True)\n","          sampled_two = np.random.choice(two_digit_array, int(total_num_in_set*0), replace=True)\n","          sampled_three = np.random.choice(three_digit_array, int(total_num_in_set*0), replace=True)\n","        elif phase == 2:\n","          sampled_one = np.random.choice(one_digit_array, int(total_num_in_set*0.3), replace=True)\n","          sampled_two = np.random.choice(two_digit_array, int(total_num_in_set*0.7), replace=True)\n","          sampled_three = np.random.choice(three_digit_array, int(total_num_in_set*0), replace=True)\n","        elif phase == 3:\n","          sampled_one = np.random.choice(one_digit_array, int(total_num_in_set*0.15), replace=True)\n","          sampled_two = np.random.choice(two_digit_array, int(total_num_in_set*0.2), replace=True)\n","          sampled_three = np.random.choice(three_digit_array, int(total_num_in_set*0.65), replace=True)\n","        # Combine all sampled numbers into one dataset\n","        new_dataset = np.concatenate([sampled_one, sampled_two, sampled_three])\n","\n","        return new_dataset\n","\n","\n","    if mode == 'train':\n","      sampled_set = sample_from_arrays(train_set_1, train_set_2, train_set_3, phase)\n","      # random choose a and b from set\n","      a = np.random.choice(sampled_set, batch_size)\n","      b = np.random.choice(sampled_set, batch_size)\n","      c = a + b\n","    else:\n","      a = np.random.choice(test, batch_size)\n","      b = np.random.choice(test, batch_size)\n","      c = a + b\n","\n","    x_list, y_list = [], []\n","    for i, j, k in zip(a, b, c):\n","        # construct X: \"i+j=k&\"\n","        x_str = f\"{i}+{j}={k}&\"\n","        # print(x_str)\n","        x_encoded = encode(x_str)\n","        x_padded = x_encoded + [padding_token_index] * (block_size - len(x_encoded))\n","        x_list.append(torch.tensor(x_padded, dtype=torch.int64))\n","\n","        # construct Y: \"k&\"\n","        y_encoded = encode(x_str)[1:]\n","        y_encoded.append(end_token_index)\n","        y_padded = y_encoded + [padding_token_index] * (block_size - len(y_encoded))\n","        y_list.append(torch.tensor(y_padded, dtype=torch.int64))\n","\n","    x_tensor = torch.stack(x_list).to(device)\n","    y_tensor = torch.stack(y_list).to(device)\n","    return x_tensor, y_tensor"],"metadata":{"id":"yQPUNSWqZO2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_batch(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fbr7rBey6SD","executionInfo":{"status":"ok","timestamp":1738871134922,"user_tz":300,"elapsed":728,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"85d18d2a-18ef-4336-d540-b20dcf64e2dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 4,  1,  3, 11,  4,  8,  5, 10,  8,  9,  8, 12, 13, 13, 13],\n","         [ 4,  5,  4, 11,  7,  7,  5, 10,  1,  2,  2,  9, 12, 13, 13],\n","         [ 6, 11,  3,  8,  8, 10,  3,  9,  4, 12, 13, 13, 13, 13, 13],\n","         [ 1,  8,  6, 11,  9,  8, 10,  2,  8,  4, 12, 13, 13, 13, 13],\n","         [ 2,  0,  2, 11,  6,  5, 10,  2,  6,  7, 12, 13, 13, 13, 13],\n","         [ 5,  0,  8, 11,  7,  6,  0, 10,  1,  2,  6,  8, 12, 13, 13],\n","         [ 6,  0, 11,  1,  2,  4, 10,  1,  8,  4, 12, 13, 13, 13, 13],\n","         [ 5,  6,  3, 11,  4,  9,  6, 10,  1,  0,  5,  9, 12, 13, 13],\n","         [ 6,  4,  8, 11,  3, 10,  6,  5,  1, 12, 13, 13, 13, 13, 13],\n","         [ 2,  2,  9, 11,  3,  2, 10,  2,  6,  1, 12, 13, 13, 13, 13],\n","         [ 6,  4,  9, 11,  1,  2,  4, 10,  7,  7,  3, 12, 13, 13, 13],\n","         [ 9,  1,  6, 11,  9,  8,  8, 10,  1,  9,  0,  4, 12, 13, 13],\n","         [ 1,  9,  2, 11,  6,  0, 10,  2,  5,  2, 12, 13, 13, 13, 13],\n","         [ 1,  0, 11,  2,  9,  9, 10,  3,  0,  9, 12, 13, 13, 13, 13],\n","         [ 7,  3,  1, 11,  7,  4,  1, 10,  1,  4,  7,  2, 12, 13, 13],\n","         [ 7,  7,  1, 11,  4,  3, 10,  8,  1,  4, 12, 13, 13, 13, 13],\n","         [ 1,  7,  9, 11,  9,  8,  2, 10,  1,  1,  6,  1, 12, 13, 13],\n","         [ 3,  7,  1, 11,  8, 10,  3,  7,  9, 12, 13, 13, 13, 13, 13],\n","         [ 3,  2,  6, 11,  4,  1,  3, 10,  7,  3,  9, 12, 13, 13, 13],\n","         [ 7,  1,  0, 11,  9,  3,  2, 10,  1,  6,  4,  2, 12, 13, 13],\n","         [ 8, 11,  8,  6,  9, 10,  8,  7,  7, 12, 13, 13, 13, 13, 13],\n","         [ 8, 11,  6,  0, 10,  6,  8, 12, 13, 13, 13, 13, 13, 13, 13],\n","         [ 3,  1,  1, 11,  2,  0,  9, 10,  5,  2,  0, 12, 13, 13, 13],\n","         [ 5, 11,  7,  1,  4, 10,  7,  1,  9, 12, 13, 13, 13, 13, 13],\n","         [ 1,  8, 11,  2,  0,  9, 10,  2,  2,  7, 12, 13, 13, 13, 13],\n","         [ 2,  8,  0, 11,  3,  1, 10,  3,  1,  1, 12, 13, 13, 13, 13],\n","         [ 7, 11,  2,  2,  3, 10,  2,  3,  0, 12, 13, 13, 13, 13, 13],\n","         [ 0, 11,  5, 10,  5, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n","         [ 7,  7, 11,  1,  4,  5, 10,  2,  2,  2, 12, 13, 13, 13, 13],\n","         [ 3,  8,  6, 11,  6, 10,  3,  9,  2, 12, 13, 13, 13, 13, 13],\n","         [ 6,  2, 11,  6,  2, 10,  1,  2,  4, 12, 13, 13, 13, 13, 13],\n","         [ 3, 11,  6,  7,  7, 10,  6,  8,  0, 12, 13, 13, 13, 13, 13]],\n","        device='cuda:0'),\n"," tensor([[ 1,  3, 11,  4,  8,  5, 10,  8,  9,  8, 12, 12, 13, 13, 13],\n","         [ 5,  4, 11,  7,  7,  5, 10,  1,  2,  2,  9, 12, 12, 13, 13],\n","         [11,  3,  8,  8, 10,  3,  9,  4, 12, 12, 13, 13, 13, 13, 13],\n","         [ 8,  6, 11,  9,  8, 10,  2,  8,  4, 12, 12, 13, 13, 13, 13],\n","         [ 0,  2, 11,  6,  5, 10,  2,  6,  7, 12, 12, 13, 13, 13, 13],\n","         [ 0,  8, 11,  7,  6,  0, 10,  1,  2,  6,  8, 12, 12, 13, 13],\n","         [ 0, 11,  1,  2,  4, 10,  1,  8,  4, 12, 12, 13, 13, 13, 13],\n","         [ 6,  3, 11,  4,  9,  6, 10,  1,  0,  5,  9, 12, 12, 13, 13],\n","         [ 4,  8, 11,  3, 10,  6,  5,  1, 12, 12, 13, 13, 13, 13, 13],\n","         [ 2,  9, 11,  3,  2, 10,  2,  6,  1, 12, 12, 13, 13, 13, 13],\n","         [ 4,  9, 11,  1,  2,  4, 10,  7,  7,  3, 12, 12, 13, 13, 13],\n","         [ 1,  6, 11,  9,  8,  8, 10,  1,  9,  0,  4, 12, 12, 13, 13],\n","         [ 9,  2, 11,  6,  0, 10,  2,  5,  2, 12, 12, 13, 13, 13, 13],\n","         [ 0, 11,  2,  9,  9, 10,  3,  0,  9, 12, 12, 13, 13, 13, 13],\n","         [ 3,  1, 11,  7,  4,  1, 10,  1,  4,  7,  2, 12, 12, 13, 13],\n","         [ 7,  1, 11,  4,  3, 10,  8,  1,  4, 12, 12, 13, 13, 13, 13],\n","         [ 7,  9, 11,  9,  8,  2, 10,  1,  1,  6,  1, 12, 12, 13, 13],\n","         [ 7,  1, 11,  8, 10,  3,  7,  9, 12, 12, 13, 13, 13, 13, 13],\n","         [ 2,  6, 11,  4,  1,  3, 10,  7,  3,  9, 12, 12, 13, 13, 13],\n","         [ 1,  0, 11,  9,  3,  2, 10,  1,  6,  4,  2, 12, 12, 13, 13],\n","         [11,  8,  6,  9, 10,  8,  7,  7, 12, 12, 13, 13, 13, 13, 13],\n","         [11,  6,  0, 10,  6,  8, 12, 12, 13, 13, 13, 13, 13, 13, 13],\n","         [ 1,  1, 11,  2,  0,  9, 10,  5,  2,  0, 12, 12, 13, 13, 13],\n","         [11,  7,  1,  4, 10,  7,  1,  9, 12, 12, 13, 13, 13, 13, 13],\n","         [ 8, 11,  2,  0,  9, 10,  2,  2,  7, 12, 12, 13, 13, 13, 13],\n","         [ 8,  0, 11,  3,  1, 10,  3,  1,  1, 12, 12, 13, 13, 13, 13],\n","         [11,  2,  2,  3, 10,  2,  3,  0, 12, 12, 13, 13, 13, 13, 13],\n","         [11,  5, 10,  5, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n","         [ 7, 11,  1,  4,  5, 10,  2,  2,  2, 12, 12, 13, 13, 13, 13],\n","         [ 8,  6, 11,  6, 10,  3,  9,  2, 12, 12, 13, 13, 13, 13, 13],\n","         [ 2, 11,  6,  2, 10,  1,  2,  4, 12, 12, 13, 13, 13, 13, 13],\n","         [11,  6,  7,  7, 10,  6,  8,  0, 12, 12, 13, 13, 13, 13, 13]],\n","        device='cuda:0'))"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n","\n","    def __init__(self, ndim, bias=True): # class constructor\n","        super().__init__()\n","        # nn.Parameter, pytorch optimize will update the value of this parameter during training\n","        self.weight = nn.Parameter(torch.ones(ndim)) # trainable parameter\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None # trainable parameter\n","\n","    def forward(self, input):\n","        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout, block_size, bias=True):\n","        super().__init__()\n","        assert n_embd % n_head == 0, \"Embedding dimension must be divisible by the number of heads.\"\n","\n","        # Store hyperparameters\n","        self.n_head = n_head\n","        self.n_embd = n_embd\n","        self.dropout = dropout\n","        self.block_size = block_size\n","\n","        # Key, Query, Value projections\n","        self.c_attn = nn.Linear(n_embd, 3 * n_embd, bias=bias)\n","        # Output projection\n","        self.c_proj = nn.Linear(n_embd, n_embd, bias=bias)\n","        # Regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","\n","        # Check for Flash Attention availability\n","        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n","        if not self.flash:\n","            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n","            # Causal mask for slow attention\n","            self.register_buffer(\n","                \"bias\",\n","                torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size)\n","            )\n","\n","    def forward(self, x):\n","        B, T, C = x.size()  # Batch size, sequence length, embedding dimension\n","\n","        # Compute Q, K, V\n","        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)  # Split into Q, K, V (B, T, n_embd)\n","\n","        # Reshape for multi-head attention\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","\n","        # Flash Attention or fallback to manual implementation\n","        if self.flash:\n","            y = torch.nn.functional.scaled_dot_product_attention(\n","                q, k, v,\n","                attn_mask=None,\n","                dropout_p=self.dropout if self.training else 0,\n","                is_causal=True\n","            )\n","        else:\n","            # Manual attention with causal masking\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))  # Scaled dot product\n","            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))  # Apply causal mask\n","            att = F.softmax(att, dim=-1)  # Normalize attention scores\n","            att = self.attn_dropout(att)\n","            y = att @ v  # Apply attention weights to values (B, n_head, T, head_size)\n","\n","        # Reshape back to original format\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)  # Reassemble heads\n","\n","        # Output projection and residual dropout\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y\n","\n","class MLP(nn.Module): # FFN\n","\n","    def __init__(self, n_embd, dropout, bias=True):\n","        super().__init__()\n","        self.c_fc    = nn.Linear(n_embd, 4 * n_embd, bias=bias)\n","        self.gelu    = nn.GELU() # nonlinear activation function\n","        self.c_proj  = nn.Linear(4 * n_embd, n_embd, bias=bias)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.c_fc(x)\n","        x = self.gelu(x)\n","        x = self.c_proj(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class Block(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout, block_size, bias=True):\n","        super().__init__()\n","        # LayerNorm and CausalSelfAttention with explicit parameters\n","        self.ln_1 = LayerNorm(n_embd, bias=bias)\n","        self.attn = CausalSelfAttention(n_embd, n_head, dropout, block_size, bias=bias)\n","        self.ln_2 = LayerNorm(n_embd, bias=bias)\n","        self.mlp = MLP(n_embd, dropout, bias=bias)  # MLP with explicit parameters\n","\n","    def forward(self, x):\n","        # Apply residual connection and pre-normalization\n","        x = x + self.attn(self.ln_1(x))  # Apply LayerNorm before attention\n","        x = x + self.mlp(self.ln_2(x))  # Apply LayerNorm before MLP\n","        return x\n","\n","\n","class GPT(nn.Module):\n","\n","    def __init__(self, vocab_size, block_size, n_embd, n_layer, n_head, dropout, bias=True):\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        super().__init__()\n","        assert vocab_size is not None\n","        assert block_size is not None\n","        self.vocab_size = vocab_size\n","        self.block_size = block_size\n","        self.n_embd = n_embd\n","        self.n_layer = n_layer\n","        self.n_head = n_head\n","        self.dropout = dropout\n","        self.bias = bias\n","\n","        self.transformer = nn.ModuleDict(dict(\n","            wte = nn.Embedding(vocab_size, n_embd), # token embeddings\n","            wpe = nn.Embedding(block_size, n_embd), # positional embeddings\n","            drop = nn.Dropout(dropout),\n","            h = nn.ModuleList([Block(n_embd, n_head, dropout, block_size, bias=bias) for _ in range(n_layer)]), # a stack of n_layer blocks\n","            ln_f = LayerNorm(n_embd, bias=bias), # final layer norm\n","        ))\n","        self.lm_head = nn.Linear(n_embd, vocab_size, bias=False) # projects the final transformer output to the vocab size\n","\n","        # init all weights\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        device = idx.device\n","        b, t = idx.size()\n","        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.cblock_size}\"\n","        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n","\n","        # forward the GPT model itself\n","        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n","        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n","        x = self.transformer.drop(tok_emb + pos_emb)\n","        for block in self.transformer.h:\n","            x = block(x)\n","        x = self.transformer.ln_f(x)\n","\n","        logits = self.lm_head(x)\n","\n","        loss = None\n","\n","        if targets is not None:\n","            # if we are given some desired targets also calculate the loss\n","            logits = self.lm_head(x)\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=13)\n","            # inference-time mini-optimization: only forward the lm_head on the very last position\n","            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n","            # loss = None\n","\n","        return logits, loss"],"metadata":{"id":"XVIg1aizaT7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_iters = 200\n","\n","@torch.no_grad()\n","def estimate_loss(phase, models):\n","    out = {}\n","    models.eval()\n","    for split in ['train', 'val']:\n","      losses = torch.zeros(eval_iters)\n","      for k in range(eval_iters):\n","          X, Y = get_batch(phase, mode=split)\n","          padding_mask_x = (X != padding_token_index).long()\n","          logits, loss = models(X, Y)\n","          losses[k] = loss.item()\n","      out[split] = losses.mean()\n","    models.train()\n","    return out"],"metadata":{"id":"cNC6DqTgcbZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# batch_size = 32 # how many independent sequences will we process in parallel?\n","block_size = 15 # what is the maximum context length for predictions?\n","max_iters = 50000\n","# num_epochs = 100\n","eval_interval = 100\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 20\n","n_embd = 1024\n","n_head = 64\n","n_layer = 8\n","dropout = 0.0\n","# # torch.manual_seed(1337)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed_all(1337)\n","bias = True # if using bias inside all Linear layers\n","vocab_size = len(vocab)"],"metadata":{"id":"xOdwJ26Ax2e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(model, acc_sample):\n","    correct = 0\n","    for j in range(100):\n","        if acc_sample == \"all\":\n","            a = np.random.choice(np.arange(1000), 1)\n","            b = np.random.choice(np.arange(1000), 1)\n","        elif acc_sample == \"test\":\n","            a = np.random.choice(test, 1)\n","            b = np.random.choice(test, 1)\n","\n","        c = a + b\n","        input = f\"{a.item()}+{b.item()}=\"\n","        context = torch.tensor(encode(input), dtype=torch.long, device=device)\n","        output = generate(model, context, 100, 1)\n","        if output == f\"{a.item()}+{b.item()}={c.item()}\":\n","            correct += 1\n","    print(f\"Accuracy for addition in {acc_sample}: {correct / 100} \")\n","    return correct / 100"],"metadata":{"id":"eMP3xYrvpdoW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate(model, idx, max_new_tokens, temperature=1.0, top_k=None):\n","    \"\"\"\n","    Generate a sequence of tokens given an initial sequence.\n","\n","    Parameters:\n","        model (nn.Module): The model used for generation.\n","        idx (torch.Tensor or list): Initial sequence of indices (LongTensor of shape (b,t)).\n","        max_new_tokens (int): Number of new tokens to generate.\n","        temperature (float): Scaling factor for logits before softmax.\n","        top_k (int, optional): If specified, restricts sampling to top k tokens.\n","\n","    Returns:\n","        torch.Tensor: The generated sequence.\n","    \"\"\"\n","    idx = idx.unsqueeze(0) if idx.dim() == 1 else idx\n","    idx = torch.tensor(idx, device=model.device) if not isinstance(idx, torch.Tensor) else idx.to(model.device)\n","\n","    for _ in range(max_new_tokens):\n","        # Ensure context length does not exceed model's block size\n","        idx_cond = idx if idx.size(1) <= model.block_size else idx[:, -model.block_size:]\n","\n","        # Forward pass to get logits\n","        logits, _ = model(idx_cond)\n","\n","        # Extract logits for the last token and apply temperature scaling\n","        logits = logits[:, -1, :] / temperature\n","\n","        # Apply top-k filtering if necessary\n","        if top_k is not None:\n","            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n","            logits[logits < v[:, [-1]]] = -float('Inf')\n","\n","        # Convert logits to probabilities\n","        probs = F.softmax(logits, dim=-1)\n","\n","        # Sample next token\n","        idx_next = torch.multinomial(probs, num_samples=1)\n","\n","        if idx_next == end_token_index:\n","            break\n","        # Append sampled token to sequence\n","\n","        # Append sampled token to sequence\n","        idx = torch.cat((idx, idx_next), dim=1)\n","\n","    return decode(idx.tolist()[0])\n"],"metadata":{"id":"sEKyA9IlOe5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GPT(vocab_size, block_size, n_embd, n_layer, n_head, dropout, bias=bias)\n","m = model.to(device)"],"metadata":{"id":"DPl7iF7e2D-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"],"metadata":{"id":"snZoFt8qe76q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the number of parameters in the model\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","phase = 1\n","best_acc_all = 0\n","best_acc_test = 0\n","counter = 0\n","patience = 20\n","best_loss = float('inf')\n","\n","for iter in tqdm(range(max_iters), desc=\"Training Progress\"):\n","    if iter > 1000:\n","      phase = 2\n","    if iter > 5000:\n","      phase = 3\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss(phase, model)\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","        if iter > 5000:\n","            acc_all = accuracy(model, \"all\")\n","            acc_test = accuracy(model, \"test\")\n","            if acc_all > best_acc_all or acc_test > best_acc_test or losses['val'] < best_loss:\n","                best_acc_all = max(best_acc_all, acc_all)\n","                best_acc_test = max(best_acc_test, acc_test)\n","                best_loss = min(best_loss, losses['val'])\n","            else:\n","              counter += 1\n","              if counter >= patience:\n","                print(f\"Early Stopping at iteration {iter}\")\n","                break\n","\n","    # sample a batch of data\n","\n","    xb, yb = get_batch(phase)\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n"],"metadata":{"id":"odtqfBE0swtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738872606120,"user_tz":300,"elapsed":629054,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"6251207c-1aca-4eb1-9ff7-35ac831035ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100.815872 M parameters\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 5/50000 [00:00<1:19:10, 10.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 0: train loss 3.2047, val loss 2.9880\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 105/50000 [00:04<43:07, 19.29it/s]"]},{"output_type":"stream","name":"stdout","text":["step 100: train loss 0.3378, val loss 4.9608\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 205/50000 [00:07<43:06, 19.25it/s]"]},{"output_type":"stream","name":"stdout","text":["step 200: train loss 0.3312, val loss 5.2377\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 305/50000 [00:11<42:57, 19.28it/s]"]},{"output_type":"stream","name":"stdout","text":["step 300: train loss 0.3193, val loss 5.4564\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 405/50000 [00:14<42:48, 19.31it/s]"]},{"output_type":"stream","name":"stdout","text":["step 400: train loss 0.3210, val loss 5.6153\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 505/50000 [00:18<42:44, 19.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 500: train loss 0.3235, val loss 5.7180\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 605/50000 [00:21<43:22, 18.98it/s]"]},{"output_type":"stream","name":"stdout","text":["step 600: train loss 0.3193, val loss 5.7671\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|▏         | 705/50000 [00:25<42:34, 19.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 700: train loss 0.3211, val loss 5.8591\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 805/50000 [00:28<43:08, 19.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 800: train loss 0.3180, val loss 5.9443\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 905/50000 [00:32<42:25, 19.29it/s]"]},{"output_type":"stream","name":"stdout","text":["step 900: train loss 0.3161, val loss 5.9732\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 1005/50000 [00:35<42:38, 19.15it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1000: train loss 0.3250, val loss 6.0218\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 1105/50000 [00:39<42:14, 19.29it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1100: train loss 1.1853, val loss 3.9818\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 1205/50000 [00:42<42:15, 19.25it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1200: train loss 1.0356, val loss 4.0120\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 1305/50000 [00:46<42:09, 19.25it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1300: train loss 0.9286, val loss 4.1377\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 1405/50000 [00:49<42:36, 19.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1400: train loss 0.8338, val loss 4.3146\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 1505/50000 [00:53<42:03, 19.22it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1500: train loss 0.7992, val loss 4.3452\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 1605/50000 [00:56<41:58, 19.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1600: train loss 0.7786, val loss 4.3786\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 1705/50000 [01:00<41:51, 19.23it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1700: train loss 0.7716, val loss 4.5741\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▎         | 1805/50000 [01:04<41:36, 19.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1800: train loss 0.7540, val loss 4.5640\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 1905/50000 [01:07<41:46, 19.19it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1900: train loss 0.7555, val loss 4.6978\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 2005/50000 [01:11<41:22, 19.33it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2000: train loss 0.7436, val loss 4.7851\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 2105/50000 [01:14<41:19, 19.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2100: train loss 0.7450, val loss 4.8725\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 2205/50000 [01:18<41:20, 19.27it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2200: train loss 0.7417, val loss 4.9422\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 2305/50000 [01:21<41:14, 19.28it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2300: train loss 0.7548, val loss 4.9925\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 2405/50000 [01:25<41:17, 19.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2400: train loss 0.7343, val loss 5.0675\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 2505/50000 [01:28<41:13, 19.20it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2500: train loss 0.7310, val loss 5.1214\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 2605/50000 [01:32<40:57, 19.28it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2600: train loss 0.7411, val loss 5.0965\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 2705/50000 [01:35<40:49, 19.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2700: train loss 0.7369, val loss 5.2780\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 2805/50000 [01:39<40:46, 19.29it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2800: train loss 0.7377, val loss 5.3436\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 2905/50000 [01:42<40:51, 19.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2900: train loss 0.7357, val loss 5.2244\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 3005/50000 [01:46<40:41, 19.25it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3000: train loss 0.7370, val loss 5.2905\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 3105/50000 [01:49<40:44, 19.19it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3100: train loss 0.7270, val loss 5.3071\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▋         | 3205/50000 [01:53<40:40, 19.17it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3200: train loss 0.7281, val loss 5.4161\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 3305/50000 [01:56<40:21, 19.28it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3300: train loss 0.7321, val loss 5.3411\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 3405/50000 [02:00<40:13, 19.31it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3400: train loss 0.7231, val loss 5.3789\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 3505/50000 [02:03<40:15, 19.25it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3500: train loss 0.7293, val loss 5.2724\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 3605/50000 [02:07<40:05, 19.28it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3600: train loss 0.7289, val loss 5.4539\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 3705/50000 [02:10<40:09, 19.22it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3700: train loss 0.7256, val loss 5.5079\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 3805/50000 [02:14<39:57, 19.27it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3800: train loss 0.7263, val loss 5.6023\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 3905/50000 [02:17<40:01, 19.20it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3900: train loss 0.7225, val loss 5.5903\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 4005/50000 [02:21<39:56, 19.19it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4000: train loss 0.7242, val loss 5.7161\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 4105/50000 [02:24<39:48, 19.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4100: train loss 0.7269, val loss 5.6001\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 4205/50000 [02:28<39:42, 19.22it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4200: train loss 0.7241, val loss 5.6924\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▊         | 4305/50000 [02:31<39:26, 19.31it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4300: train loss 0.7184, val loss 5.6620\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 4405/50000 [02:35<39:36, 19.18it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4400: train loss 0.7245, val loss 5.8104\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 4505/50000 [02:39<39:35, 19.15it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4500: train loss 0.7239, val loss 5.7831\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 4605/50000 [02:42<39:16, 19.27it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4600: train loss 0.7292, val loss 5.8372\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 4705/50000 [02:46<39:19, 19.20it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4700: train loss 0.7210, val loss 5.8918\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 4805/50000 [02:49<39:09, 19.24it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4800: train loss 0.7195, val loss 5.8638\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 4905/50000 [02:53<39:03, 19.24it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4900: train loss 0.7280, val loss 5.9611\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 5004/50000 [02:56<42:40, 17.57it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5000: train loss 0.7227, val loss 6.0061\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 5100/50000 [02:59<23:20, 32.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5100: train loss 1.5422, val loss 1.5720\n","Accuracy for addition in all: 0.01 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  10%|█         | 5104/50000 [03:03<4:07:50,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.0 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 5200/50000 [03:06<23:18, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5200: train loss 1.4169, val loss 1.4829\n","Accuracy for addition in all: 0.01 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  10%|█         | 5204/50000 [03:10<4:05:37,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.0 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 5300/50000 [03:13<23:17, 31.99it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5300: train loss 1.3504, val loss 1.4372\n","Accuracy for addition in all: 0.01 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  11%|█         | 5304/50000 [03:17<4:09:48,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.02 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 5400/50000 [03:20<23:13, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5400: train loss 1.2882, val loss 1.3946\n","Accuracy for addition in all: 0.02 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  11%|█         | 5404/50000 [03:25<4:08:14,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.01 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 5500/50000 [03:28<23:10, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5500: train loss 1.2221, val loss 1.3073\n","Accuracy for addition in all: 0.06 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  11%|█         | 5504/50000 [03:32<4:03:39,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.04 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 5600/50000 [03:35<23:06, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5600: train loss 1.1933, val loss 1.2761\n","Accuracy for addition in all: 0.11 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  11%|█         | 5604/50000 [03:39<4:02:48,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.03 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█▏        | 5700/50000 [03:42<23:04, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5700: train loss 1.1748, val loss 1.2227\n","Accuracy for addition in all: 0.22 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  11%|█▏        | 5704/50000 [03:46<4:07:51,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.16 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 5800/50000 [03:49<23:09, 31.80it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5800: train loss 1.1391, val loss 1.1906\n","Accuracy for addition in all: 0.18 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  12%|█▏        | 5804/50000 [03:53<4:14:06,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.23 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 5900/50000 [03:56<22:57, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5900: train loss 1.1500, val loss 1.2170\n","Accuracy for addition in all: 0.25 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  12%|█▏        | 5904/50000 [04:01<4:11:35,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.17 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 6000/50000 [04:04<22:53, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6000: train loss 1.1338, val loss 1.1940\n","Accuracy for addition in all: 0.22 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  12%|█▏        | 6004/50000 [04:08<4:06:09,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.2 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 6100/50000 [04:11<22:49, 32.06it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6100: train loss 1.1124, val loss 1.1788\n","Accuracy for addition in all: 0.25 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  12%|█▏        | 6104/50000 [04:15<4:08:48,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.31 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 6200/50000 [04:18<22:47, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6200: train loss 1.1183, val loss 1.1890\n","Accuracy for addition in all: 0.36 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  12%|█▏        | 6204/50000 [04:22<4:03:26,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.18 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 6300/50000 [04:25<22:54, 31.80it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6300: train loss 1.1052, val loss 1.1862\n","Accuracy for addition in all: 0.39 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  13%|█▎        | 6304/50000 [04:29<3:59:48,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.3 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 6400/50000 [04:32<22:40, 32.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6400: train loss 1.1034, val loss 1.1679\n","Accuracy for addition in all: 0.35 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  13%|█▎        | 6404/50000 [04:36<4:07:24,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.31 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 6500/50000 [04:39<22:36, 32.07it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6500: train loss 1.0856, val loss 1.1652\n","Accuracy for addition in all: 0.33 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  13%|█▎        | 6504/50000 [04:44<3:58:22,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.29 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 6600/50000 [04:47<22:40, 31.90it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6600: train loss 1.0791, val loss 1.1587\n","Accuracy for addition in all: 0.35 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  13%|█▎        | 6604/50000 [04:51<4:08:51,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.38 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 6700/50000 [04:54<22:32, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6700: train loss 1.0820, val loss 1.1648\n","Accuracy for addition in all: 0.41 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  13%|█▎        | 6704/50000 [04:58<4:02:48,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.34 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▎        | 6800/50000 [05:01<22:33, 31.92it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6800: train loss 1.0828, val loss 1.1635\n","Accuracy for addition in all: 0.3 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  14%|█▎        | 6804/50000 [05:05<4:09:36,  2.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.28 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 6900/50000 [05:08<22:23, 32.09it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6900: train loss 1.0796, val loss 1.1719\n","Accuracy for addition in all: 0.32 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  14%|█▍        | 6904/50000 [05:13<4:04:10,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.28 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 7000/50000 [05:16<22:23, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7000: train loss 1.0643, val loss 1.1561\n","Accuracy for addition in all: 0.31 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  14%|█▍        | 7004/50000 [05:20<3:56:14,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.26 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 7100/50000 [05:23<22:29, 31.79it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7100: train loss 1.0797, val loss 1.1609\n","Accuracy for addition in all: 0.36 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  14%|█▍        | 7104/50000 [05:27<3:56:01,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.36 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 7200/50000 [05:30<22:15, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7200: train loss 1.0653, val loss 1.1749\n","Accuracy for addition in all: 0.44 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  14%|█▍        | 7204/50000 [05:34<4:01:11,  2.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.35 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 7300/50000 [05:37<22:13, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7300: train loss 1.0640, val loss 1.1637\n","Accuracy for addition in all: 0.43 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  15%|█▍        | 7304/50000 [05:41<3:53:27,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.29 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 7400/50000 [05:44<22:10, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7400: train loss 1.0647, val loss 1.1502\n","Accuracy for addition in all: 0.36 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  15%|█▍        | 7404/50000 [05:49<4:06:46,  2.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.35 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 7500/50000 [05:51<22:07, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7500: train loss 1.0634, val loss 1.1726\n","Accuracy for addition in all: 0.41 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  15%|█▌        | 7504/50000 [05:56<3:52:05,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.35 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 7600/50000 [05:59<22:02, 32.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7600: train loss 1.0595, val loss 1.1670\n","Accuracy for addition in all: 0.39 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  15%|█▌        | 7604/50000 [06:03<3:55:06,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.38 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 7700/50000 [06:06<22:02, 31.99it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7700: train loss 1.0543, val loss 1.1541\n","Accuracy for addition in all: 0.38 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  15%|█▌        | 7704/50000 [06:10<3:55:56,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.34 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▌        | 7800/50000 [06:13<21:55, 32.07it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7800: train loss 1.0458, val loss 1.1515\n","Accuracy for addition in all: 0.37 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  16%|█▌        | 7804/50000 [06:17<3:57:10,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.51 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▌        | 7900/50000 [06:20<22:01, 31.86it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7900: train loss 1.0385, val loss 1.1546\n","Accuracy for addition in all: 0.46 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  16%|█▌        | 7904/50000 [06:24<3:59:49,  2.93it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.43 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▌        | 8000/50000 [06:27<21:51, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8000: train loss 1.0471, val loss 1.1482\n","Accuracy for addition in all: 0.45 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  16%|█▌        | 8004/50000 [06:32<4:01:02,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.45 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▌        | 8100/50000 [06:35<21:50, 31.98it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8100: train loss 1.0437, val loss 1.1461\n","Accuracy for addition in all: 0.48 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  16%|█▌        | 8104/50000 [06:39<3:53:22,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.37 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▋        | 8200/50000 [06:42<21:45, 32.02it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8200: train loss 1.0318, val loss 1.1394\n","Accuracy for addition in all: 0.44 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  16%|█▋        | 8204/50000 [06:46<3:55:02,  2.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.41 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  17%|█▋        | 8300/50000 [06:49<21:45, 31.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8300: train loss 1.0426, val loss 1.1346\n","Accuracy for addition in all: 0.45 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  17%|█▋        | 8304/50000 [06:53<3:51:16,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.58 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  17%|█▋        | 8400/50000 [06:56<21:41, 31.97it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8400: train loss 1.0269, val loss 1.1168\n","Accuracy for addition in all: 0.49 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  17%|█▋        | 8404/50000 [07:00<3:53:17,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.4 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  17%|█▋        | 8500/50000 [07:03<21:40, 31.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8500: train loss 1.0141, val loss 1.1261\n","Accuracy for addition in all: 0.56 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  17%|█▋        | 8504/50000 [07:08<3:55:46,  2.93it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.57 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  17%|█▋        | 8600/50000 [07:11<21:33, 32.02it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8600: train loss 1.0122, val loss 1.1176\n","Accuracy for addition in all: 0.63 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  17%|█▋        | 8604/50000 [07:15<3:49:36,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.64 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  17%|█▋        | 8700/50000 [07:18<21:33, 31.92it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8700: train loss 1.0178, val loss 1.0995\n","Accuracy for addition in all: 0.63 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  17%|█▋        | 8704/50000 [07:22<3:56:54,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.5 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  18%|█▊        | 8800/50000 [07:25<21:30, 31.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8800: train loss 1.0027, val loss 1.1043\n","Accuracy for addition in all: 0.6 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  18%|█▊        | 8804/50000 [07:29<3:52:06,  2.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.49 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  18%|█▊        | 8900/50000 [07:32<21:24, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8900: train loss 1.0040, val loss 1.0907\n","Accuracy for addition in all: 0.7 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  18%|█▊        | 8904/50000 [07:37<3:58:28,  2.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.59 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  18%|█▊        | 9000/50000 [07:40<21:19, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9000: train loss 1.0006, val loss 1.0975\n","Accuracy for addition in all: 0.67 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  18%|█▊        | 9004/50000 [07:44<3:55:14,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.6 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  18%|█▊        | 9100/50000 [07:47<21:23, 31.87it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9100: train loss 0.9870, val loss 1.0904\n","Accuracy for addition in all: 0.62 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  18%|█▊        | 9104/50000 [07:51<3:48:43,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.63 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  18%|█▊        | 9200/50000 [07:54<21:15, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9200: train loss 0.9970, val loss 1.0890\n","Accuracy for addition in all: 0.7 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  18%|█▊        | 9204/50000 [07:58<3:43:15,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.66 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  19%|█▊        | 9300/50000 [08:01<21:09, 32.07it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9300: train loss 0.9956, val loss 1.0884\n","Accuracy for addition in all: 0.69 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  19%|█▊        | 9304/50000 [08:05<3:52:49,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.63 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  19%|█▉        | 9400/50000 [08:08<21:07, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9400: train loss 0.9926, val loss 1.0886\n","Accuracy for addition in all: 0.68 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  19%|█▉        | 9404/50000 [08:13<3:42:04,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.67 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  19%|█▉        | 9500/50000 [08:16<21:04, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9500: train loss 0.9890, val loss 1.0784\n","Accuracy for addition in all: 0.78 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  19%|█▉        | 9504/50000 [08:20<3:44:40,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.69 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  19%|█▉        | 9600/50000 [08:23<21:00, 32.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9600: train loss 0.9897, val loss 1.0925\n","Accuracy for addition in all: 0.67 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  19%|█▉        | 9604/50000 [08:27<3:44:02,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.64 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  19%|█▉        | 9700/50000 [08:30<21:01, 31.95it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9700: train loss 0.9865, val loss 1.0995\n","Accuracy for addition in all: 0.82 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  19%|█▉        | 9704/50000 [08:34<3:35:27,  3.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.71 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  20%|█▉        | 9800/50000 [08:37<20:55, 32.02it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9800: train loss 0.9923, val loss 1.0823\n","Accuracy for addition in all: 0.69 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  20%|█▉        | 9804/50000 [08:41<3:44:52,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.75 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  20%|█▉        | 9900/50000 [08:44<20:51, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9900: train loss 0.9854, val loss 1.0729\n","Accuracy for addition in all: 0.79 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  20%|█▉        | 9904/50000 [08:48<3:47:17,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.67 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  20%|██        | 10000/50000 [08:51<20:51, 31.96it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10000: train loss 0.9860, val loss 1.0857\n","Accuracy for addition in all: 0.87 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  20%|██        | 10004/50000 [08:55<3:46:55,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.7 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  20%|██        | 10100/50000 [08:58<20:45, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10100: train loss 0.9929, val loss 1.0764\n","Accuracy for addition in all: 0.72 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  20%|██        | 10104/50000 [09:03<3:39:41,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.78 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  20%|██        | 10200/50000 [09:06<20:55, 31.70it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10200: train loss 0.9818, val loss 1.0856\n","Accuracy for addition in all: 0.8 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  20%|██        | 10204/50000 [09:10<3:43:06,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.72 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  21%|██        | 10300/50000 [09:13<20:41, 31.99it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10300: train loss 0.9910, val loss 1.0935\n","Accuracy for addition in all: 0.79 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  21%|██        | 10304/50000 [09:17<3:39:18,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.73 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  21%|██        | 10400/50000 [09:20<20:36, 32.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10400: train loss 0.9878, val loss 1.1006\n","Accuracy for addition in all: 0.75 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  21%|██        | 10404/50000 [09:24<3:35:30,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.74 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  21%|██        | 10500/50000 [09:27<20:31, 32.06it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10500: train loss 0.9801, val loss 1.0763\n","Accuracy for addition in all: 0.82 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  21%|██        | 10504/50000 [09:31<3:36:52,  3.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.68 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  21%|██        | 10600/50000 [09:34<20:32, 31.96it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10600: train loss 0.9794, val loss 1.0758\n","Accuracy for addition in all: 0.78 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  21%|██        | 10604/50000 [09:38<3:38:09,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.75 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  21%|██▏       | 10700/50000 [09:41<20:26, 32.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10700: train loss 0.9822, val loss 1.0816\n","Accuracy for addition in all: 0.76 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  21%|██▏       | 10704/50000 [09:46<3:46:38,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.77 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  22%|██▏       | 10800/50000 [09:49<20:24, 32.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10800: train loss 0.9810, val loss 1.0727\n","Accuracy for addition in all: 0.87 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  22%|██▏       | 10804/50000 [09:53<3:41:22,  2.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.8 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  22%|██▏       | 10900/50000 [09:56<20:24, 31.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10900: train loss 0.9812, val loss 1.0752\n","Accuracy for addition in all: 0.82 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  22%|██▏       | 10904/50000 [10:00<3:33:48,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.83 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  22%|██▏       | 11000/50000 [10:03<20:18, 32.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11000: train loss 0.9740, val loss 1.0808\n","Accuracy for addition in all: 0.84 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  22%|██▏       | 11004/50000 [10:07<3:39:15,  2.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.81 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  22%|██▏       | 11100/50000 [10:10<20:12, 32.08it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11100: train loss 0.9795, val loss 1.0873\n","Accuracy for addition in all: 0.83 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  22%|██▏       | 11104/50000 [10:14<3:37:31,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.84 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  22%|██▏       | 11200/50000 [10:17<20:14, 31.96it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11200: train loss 0.9710, val loss 1.0743\n","Accuracy for addition in all: 0.87 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  22%|██▏       | 11204/50000 [10:21<3:34:24,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.84 \n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  23%|██▎       | 11300/50000 [10:24<20:14, 31.85it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11300: train loss 0.9703, val loss 1.0744\n","Accuracy for addition in all: 0.87 \n"]},{"output_type":"stream","name":"stderr","text":["\rTraining Progress:  23%|██▎       | 11300/50000 [10:28<35:54, 17.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Accuracy for addition in test: 0.79 \n","Early Stopping at iteration 11300\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["test_set = {1: test_1,\n","            2: test_12,\n","            3: test\n","            }"],"metadata":{"id":"CQaOm7Hi6nzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy_print(model, num_digits, set_type):\n","        correct = 0\n","        if set_type == \"all\":\n","          for j in range(100):\n","              a = np.random.choice(np.arange(10**num_digits), 1)\n","              b = np.random.choice(np.arange(10**num_digits), 1)\n","              c = a + b\n","              input = f\"{a.item()}+{b.item()}=\"\n","              context = torch.tensor(encode(input), dtype=torch.long, device=device)\n","              output = generate(model, context, 100, 1)\n","              if j // 10 == 0:\n","                  print(f\"Input: {input}\")\n","                  print(f\"Output: {output}\")\n","              if output == f\"{a.item()}+{b.item()}={c.item()}\":\n","                  correct += 1\n","        elif set_type == \"test\":\n","            for j in range(100):\n","                a = np.random.choice(test_set[num_digits], 1)\n","                b = np.random.choice(test_set[num_digits], 1)\n","                c = a + b\n","                input = f\"{a.item()}+{b.item()}=\"\n","                context = torch.tensor(encode(input), dtype=torch.long, device=device)\n","                output = generate(model, context, 100, 1)\n","                if j // 10 == 0:\n","                    print(f\"Input: {input}\")\n","                    print(f\"Output: {output}\")\n","                if output == f\"{a.item()}+{b.item()}={c.item()}\":\n","                    correct += 1\n","        print(f\"Accuracy for addition: {correct / 100} \")"],"metadata":{"id":"Gf-KW9gJiu6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_print(model, 1, \"all\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJBWmy5C4xIV","executionInfo":{"status":"ok","timestamp":1738873397466,"user_tz":300,"elapsed":1069,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"43af47e4-15a0-494c-dd1c-08d3af960b64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 6+5=\n","Output: 6+5=11\n","Input: 5+4=\n","Output: 5+4=9\n","Input: 0+1=\n","Output: 0+1=11\n","Input: 9+8=\n","Output: 9+8=17\n","Input: 9+7=\n","Output: 9+7=16\n","Input: 4+6=\n","Output: 4+6=10\n","Input: 1+2=\n","Output: 1+2=3\n","Input: 3+7=\n","Output: 3+7=10\n","Input: 5+4=\n","Output: 5+4=9\n","Input: 6+8=\n","Output: 6+8=14\n","Accuracy for addition: 0.81 \n"]}]},{"cell_type":"code","source":["accuracy_print(model, 1, \"test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19uycVG97nVM","executionInfo":{"status":"ok","timestamp":1738873523025,"user_tz":300,"elapsed":739,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"98278692-179f-433e-9d34-26ff5b4482c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 1+1=\n","Output: 1+1=\n","Input: 2+2=\n","Output: 2+2=8\n","Input: 2+1=\n","Output: 2+1=\n","Input: 2+1=\n","Output: 2+1=\n","Input: 1+1=\n","Output: 1+1=\n","Input: 1+1=\n","Output: 1+1=\n","Input: 2+1=\n","Output: 2+1=\n","Input: 2+1=\n","Output: 2+1=\n","Input: 1+1=\n","Output: 1+1=1\n","Input: 1+2=\n","Output: 1+2=3\n","Accuracy for addition: 0.14 \n"]}]},{"cell_type":"code","source":["accuracy_print(model, 2, \"all\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fVnQ-8h7qd8","executionInfo":{"status":"ok","timestamp":1738873422630,"user_tz":300,"elapsed":1549,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"1cfba9df-43d6-4d42-9c33-eb738e6c77dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 75+76=\n","Output: 75+76=151\n","Input: 67+8=\n","Output: 67+8=75\n","Input: 1+68=\n","Output: 1+68=72\n","Input: 78+35=\n","Output: 78+35=113\n","Input: 35+53=\n","Output: 35+53=88\n","Input: 80+79=\n","Output: 80+79=159\n","Input: 38+4=\n","Output: 38+4=42\n","Input: 38+56=\n","Output: 38+56=93\n","Input: 45+95=\n","Output: 45+95=140\n","Input: 68+2=\n","Output: 68+2=70\n","Accuracy for addition: 0.92 \n"]}]},{"cell_type":"code","source":["accuracy_print(model, 2, \"test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtV-ojTO489M","executionInfo":{"status":"ok","timestamp":1738873539202,"user_tz":300,"elapsed":1593,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"1872ec16-9a2f-41d9-c23e-fc3a8d047cb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 28+89=\n","Output: 28+89=116\n","Input: 28+29=\n","Output: 28+29=57\n","Input: 29+1=\n","Output: 29+1=20\n","Input: 2+26=\n","Output: 2+26=28\n","Input: 46+26=\n","Output: 46+26=72\n","Input: 33+29=\n","Output: 33+29=62\n","Input: 26+49=\n","Output: 26+49=75\n","Input: 40+33=\n","Output: 40+33=73\n","Input: 78+87=\n","Output: 78+87=165\n","Input: 49+87=\n","Output: 49+87=136\n","Accuracy for addition: 0.83 \n"]}]},{"cell_type":"code","source":["accuracy_print(model, 3, \"all\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKwmkwJi5AFX","executionInfo":{"status":"ok","timestamp":1738873550583,"user_tz":300,"elapsed":2010,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"1d21e613-3a6f-4891-a97b-40dac2dc4d99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 836+723=\n","Output: 836+723=1559\n","Input: 640+226=\n","Output: 640+226=866\n","Input: 748+81=\n","Output: 748+81=829\n","Input: 396+664=\n","Output: 396+664=1060\n","Input: 580+857=\n","Output: 580+857=1437\n","Input: 519+626=\n","Output: 519+626=1155\n","Input: 136+729=\n","Output: 136+729=865\n","Input: 145+883=\n","Output: 145+883=1028\n","Input: 995+234=\n","Output: 995+234=1229\n","Input: 42+773=\n","Output: 42+773=815\n","Accuracy for addition: 0.87 \n"]}]},{"cell_type":"code","source":["accuracy_print(model, 3, \"test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ibl4JWaX7xKk","executionInfo":{"status":"ok","timestamp":1738873563406,"user_tz":300,"elapsed":2065,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"9eeea7d0-83b0-4f97-c6c7-ba055f1a3fff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 519+84=\n","Output: 519+84=603\n","Input: 2+601=\n","Output: 2+601=207\n","Input: 812+315=\n","Output: 812+315=1137\n","Input: 999+590=\n","Output: 999+590=1589\n","Input: 690+294=\n","Output: 690+294=984\n","Input: 996+822=\n","Output: 996+822=1818\n","Input: 706+360=\n","Output: 706+360=1066\n","Input: 500+374=\n","Output: 500+374=874\n","Input: 709+865=\n","Output: 709+865=1574\n","Input: 614+353=\n","Output: 614+353=967\n","Accuracy for addition: 0.81 \n"]}]},{"cell_type":"code","source":["import subprocess\n","\n","os.system('git config --global user.email \"zifeibai@umich.edu\"')\n","os.system('git config --global user.name \"ZifeiBai\"')\n","\n","# 2️⃣ **Use Google Drive to store GitHub Token**\n","GITHUB_TOKEN_PATH = \"/content/drive/MyDrive/URPS/github_token.txt\"\n","if os.path.exists(GITHUB_TOKEN_PATH):\n","    with open(GITHUB_TOKEN_PATH, \"r\") as f:\n","        os.environ[\"GITHUB_TOKEN\"] = f.read().strip()\n","else:\n","    print(\"❌ GitHub Token\")\n","    exit(1)\n","\n","# 3️⃣ **Set up GitHub remote repo**\n","GIT_PATH = \"/content/drive/MyDrive/URPS/Git\"\n","REPO_URL = f\"https://{os.environ['GITHUB_TOKEN']}@github.com/ZifeiBai/URPS.git\"\n","\n","if not os.path.exists(GIT_PATH):\n","    print(f\"📁 Creating directory: {GIT_PATH}\")\n","    os.makedirs(GIT_PATH)\n","\n","# 4️⃣ **If .git/ does not exsit， need to clone**\n","if not os.path.exists(os.path.join(GIT_PATH, \".git\")):\n","    print(\"❌ Git repository not found. Cloning...\")\n","    subprocess.run(f\"rm -rf {GIT_PATH}\", shell=True, check=True)\n","    subprocess.run(f\"git clone {REPO_URL} {GIT_PATH}\", shell=True, check=True)\n","\n","# 5️⃣ **Enter Git repo**\n","os.chdir(GIT_PATH)\n","print(\"📂 Changed working directory to:\", os.getcwd())\n","\n","\n","# 6️⃣ **Check Git status**\n","status_output = subprocess.run(\"git status\", shell=True, capture_output=True, text=True)\n","print(status_output.stdout)\n","\n","#  **Push to Git**\n","print(\"🚀 Adding files to Git...\")\n","subprocess.run(\"git add .\", shell=True, check=True)\n","\n","print(\"📝 Committing changes...\")\n","commit_output = subprocess.run('git commit -m \"Auto update from Google Colab 2.6\"', shell=True, capture_output=True, text=True)\n","print(commit_output.stdout)\n","\n","\n","\n","print(\"📤 Pushing to GitHub...\")\n","push_output = subprocess.run(\"git push origin main\", shell=True, capture_output=True, text=True)\n","if \"fatal\" in push_output.stderr or \"error:\" in push_output.stderr:\n","    print(\"❌ Real Git Push Error:\", push_output.stderr)\n","else:\n","    print(\"✅ Git Push Success!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23jaqlhaaOGQ","outputId":"e7a49be0-5a92-418d-d5b2-4df87f59fc0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["📂 Changed working directory to: /content/drive/MyDrive/URPS/Git\n"]}]}]}
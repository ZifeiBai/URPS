{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# 1️⃣ Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2EettNg4TW5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739413592314,"user_tz":300,"elapsed":22667,"user":{"displayName":"Zifei Bai","userId":"12413018286570323363"}},"outputId":"8a046e02-ea28-4680-d360-151a58b8e2ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import wandb"],"metadata":{"id":"XAclJ5EAtxyL","executionInfo":{"status":"ok","timestamp":1739758326790,"user_tz":300,"elapsed":2222,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"F-EV7vrK_q9r","executionInfo":{"status":"ok","timestamp":1739758330507,"user_tz":300,"elapsed":1304,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install plotly"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIvBVYUq7sEW","executionInfo":{"status":"ok","timestamp":1739758333331,"user_tz":300,"elapsed":2827,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"d80f3e47-6409-4009-a9f1-426d3aba8043"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n"]}]},{"cell_type":"code","source":["import plotly.graph_objects as go"],"metadata":{"id":"jWLl22bM6LSW","executionInfo":{"status":"ok","timestamp":1739758334951,"user_tz":300,"elapsed":2,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"Bz4UqDhjt1ED","executionInfo":{"status":"ok","timestamp":1739758408869,"user_tz":300,"elapsed":72256,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"3d870084-f78b-4709-a757-b1d74bb98423"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbirdyyybai\u001b[0m (\u001b[33mbirdyyybai-university-of-michigan\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-WmNzSf047AQ","executionInfo":{"status":"ok","timestamp":1739758420271,"user_tz":300,"elapsed":3675,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"outputs":[],"source":["import math\n","import inspect\n","from dataclasses import dataclass\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"]},{"cell_type":"code","source":["vocab = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', '+', '&', '*']\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","padding_token_index = 13\n","end_token_index = 12"],"metadata":{"id":"nBnXU-eyOwC4","executionInfo":{"status":"ok","timestamp":1739758420271,"user_tz":300,"elapsed":2,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# create a mapping from chars to ints\n","stoi = {ch:i for i, ch in enumerate(vocab)}\n","itos = {i:ch for i, ch in enumerate(vocab)}\n","encode = lambda s:[stoi[c] for c in s] # encoder: take a string, output a list of ints\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of ints, output a string\n","\n","print(encode(\"1+2=3&\"))\n","print(decode(encode(\"1+2=3&\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e4EbjUWPBjj","executionInfo":{"status":"ok","timestamp":1739758420272,"user_tz":300,"elapsed":2,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"777ea061-1030-4581-ef7a-e89703abd052"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 11, 2, 10, 3, 12]\n","1+2=3&\n"]}]},{"cell_type":"code","source":["# # train test split\n","# train_set_1 = np.random.choice(np.arange(10), 8, replace=False)\n","# train_set_2 = np.random.choice(np.arange(10, 100), 72, replace=False)\n","# train_set_3 = np.random.choice(np.arange(100, 1000), 720, replace=False)\n","# test_1 = np.setdiff1d(np.arange(10), train_set_1)\n","# test_2 = np.setdiff1d(np.arange(10, 100), train_set_2)\n","# test_3 = np.setdiff1d(np.arange(100, 1000), train_set_3)\n","# test_12 = np.concatenate([test_1, test_2])\n","# test = np.concatenate([test_1, test_2, test_3])\n","# print(np.sort(train_set_1))\n","# print(np.sort(train_set_2))\n","# print(np.sort(test_1))\n","# print(np.sort(test_2))\n","# print(np.sort(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_juHaFr4xuH9","executionInfo":{"status":"ok","timestamp":1739392246794,"user_tz":300,"elapsed":4,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"4fe3c7f8-0d0f-4765-b7f4-3dcaad278b90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 4 5 6 8 9]\n","[10 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 30 31 33 34 35 36\n"," 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 60 63 64 65\n"," 66 68 69 70 71 74 77 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 98 99]\n","[3 7]\n","[20 29 32 37 57 59 61 62 67 72 73 75 76 78 79 80 96 97]\n","[  3   7  20  29  32  37  57  59  61  62  67  72  73  75  76  78  79  80\n","  96  97 102 107 118 121 125 130 145 146 151 152 154 161 165 169 171 180\n"," 192 193 197 198 199 200 204 207 208 210 218 219 241 254 268 284 294 295\n"," 296 299 303 306 308 317 318 319 327 329 340 341 342 343 348 365 366 373\n"," 377 381 386 396 399 401 407 408 412 417 422 424 427 428 438 443 455 456\n"," 459 468 474 477 496 514 520 526 533 534 536 538 547 553 555 558 559 564\n"," 572 575 582 585 593 594 599 601 608 611 620 622 624 628 635 638 639 647\n"," 650 652 654 655 658 659 660 667 685 690 705 707 715 716 723 724 726 728\n"," 744 749 752 755 759 764 765 766 771 772 776 778 783 785 786 793 803 813\n"," 824 826 838 839 840 841 844 845 862 865 873 875 880 883 888 889 890 891\n"," 893 908 913 921 932 941 945 946 951 953 959 960 969 971 982 986 992 997\n"," 998 999]\n"]}]},{"cell_type":"code","source":["def get_batch(phase=None, batch_size=32, block_size=35, mode='train'):\n","\n","    if mode == 'train':\n","      # random choose a and b from set\n","      if phase != \"mix\":\n","        a = np.random.randint(10**(phase-1), 10**(phase), batch_size)\n","        b = np.random.randint(10**(phase-1), 10**(phase), batch_size)\n","        c = a + b\n","      elif phase == \"mix\":\n","        exp_a = np.random.choice(np.arange(1, 7), size=batch_size, p=[0.045, 0.075, 0.09, 0.14, 0.25, 0.40])\n","        exp_b = np.random.choice(np.arange(1, 7), size=batch_size, p=[0.045, 0.075, 0.09, 0.14, 0.25, 0.40])\n","        a = np.random.randint(10**(exp_a-1), 10**(exp_a), size=batch_size)\n","        b = np.random.randint(10**(exp_b-1), 10**(exp_b), size=batch_size)\n","        c = a + b\n","    else:\n","      if phase != \"mix\":\n","        a = np.random.randint(10**(phase-1), 10**(phase), batch_size)\n","        b = np.random.randint(10**(phase-1), 10**(phase), batch_size)\n","        c = a + b\n","      elif phase == \"mix\":\n","        exp_a = np.random.choice(np.arange(1, 7), size=batch_size, p=[0.045, 0.075, 0.09, 0.14, 0.25, 0.40])\n","        exp_b = np.random.choice(np.arange(1, 7), size=batch_size, p=[0.045, 0.075, 0.09, 0.14, 0.25, 0.40])\n","        a = np.random.randint(10**(exp_a-1), 10**(exp_a), size=batch_size)\n","        b = np.random.randint(10**(exp_b-1), 10**(exp_b), size=batch_size)\n","        c = a + b\n","\n","    x_list, y_list = [], []\n","    for i, j, k in zip(a, b, c):\n","        # construct X: \"i+j=k&\"\n","        k_str = str(k)[::-1]\n","        x_str = f\"{i}+{j}={k_str}&\"\n","        # print(x_str)\n","        x_encoded = encode(x_str)\n","        x_padded = x_encoded + [padding_token_index] * (block_size - len(x_encoded))\n","        x_list.append(torch.tensor(x_padded, dtype=torch.int64))\n","\n","        # construct Y: \"k&\"\n","        y_encoded = encode(x_str)[1:]\n","        y_encoded.append(end_token_index)\n","        y_padded = y_encoded + [padding_token_index] * (block_size - len(y_encoded))\n","        y_list.append(torch.tensor(y_padded, dtype=torch.int64))\n","\n","    x_tensor = torch.stack(x_list).to(device)\n","    y_tensor = torch.stack(y_list).to(device)\n","    return x_tensor, y_tensor"],"metadata":{"id":"yQPUNSWqZO2w","executionInfo":{"status":"ok","timestamp":1739762006909,"user_tz":300,"elapsed":274,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["get_batch(phase=\"mix\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fbr7rBey6SD","executionInfo":{"status":"ok","timestamp":1739762011701,"user_tz":300,"elapsed":985,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"fdf16388-a538-49e1-c99d-a95aef419a1b"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 7,  3,  8,  ..., 13, 13, 13],\n","         [ 6,  1,  3,  ..., 13, 13, 13],\n","         [ 7,  1,  3,  ..., 13, 13, 13],\n","         ...,\n","         [ 4,  6,  2,  ..., 13, 13, 13],\n","         [ 5,  9,  8,  ..., 13, 13, 13],\n","         [ 8,  5,  5,  ..., 13, 13, 13]], device='cuda:0'),\n"," tensor([[ 3,  8,  8,  ..., 13, 13, 13],\n","         [ 1,  3,  3,  ..., 13, 13, 13],\n","         [ 1,  3,  4,  ..., 13, 13, 13],\n","         ...,\n","         [ 6,  2,  8,  ..., 13, 13, 13],\n","         [ 9,  8,  1,  ..., 13, 13, 13],\n","         [ 5,  5,  4,  ..., 13, 13, 13]], device='cuda:0'))"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n","\n","    def __init__(self, ndim, bias=True): # class constructor\n","        super().__init__()\n","        # nn.Parameter, pytorch optimize will update the value of this parameter during training\n","        self.weight = nn.Parameter(torch.ones(ndim)) # trainable parameter\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None # trainable parameter\n","\n","    def forward(self, input):\n","        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout, block_size, bias=True):\n","        super().__init__()\n","        assert n_embd % n_head == 0, \"Embedding dimension must be divisible by the number of heads.\"\n","\n","        # Store hyperparameters\n","        self.n_head = n_head\n","        self.n_embd = n_embd\n","        self.dropout = dropout\n","        self.block_size = block_size\n","\n","        # Key, Query, Value projections\n","        self.c_attn = nn.Linear(n_embd, 3 * n_embd, bias=bias)\n","        # Output projection\n","        self.c_proj = nn.Linear(n_embd, n_embd, bias=bias)\n","        # Regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","\n","        # Check for Flash Attention availability\n","        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n","        if not self.flash:\n","            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n","            # Causal mask for slow attention\n","            self.register_buffer(\n","                \"bias\",\n","                torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size)\n","            )\n","\n","    def forward(self, x):\n","        B, T, C = x.size()  # Batch size, sequence length, embedding dimension\n","\n","        # Compute Q, K, V\n","        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)  # Split into Q, K, V (B, T, n_embd)\n","\n","        # Reshape for multi-head attention\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, n_head, T, head_size)\n","\n","        # Flash Attention or fallback to manual implementation\n","        if self.flash:\n","            y = torch.nn.functional.scaled_dot_product_attention(\n","                q, k, v,\n","                attn_mask=None,\n","                dropout_p=self.dropout if self.training else 0,\n","                is_causal=True\n","            )\n","        else:\n","            # Manual attention with causal masking\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))  # Scaled dot product\n","            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))  # Apply causal mask\n","            att = F.softmax(att, dim=-1)  # Normalize attention scores\n","            att = self.attn_dropout(att)\n","            y = att @ v  # Apply attention weights to values (B, n_head, T, head_size)\n","\n","        # Reshape back to original format\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)  # Reassemble heads\n","\n","        # Output projection and residual dropout\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y\n","\n","class MLP(nn.Module): # FFN\n","\n","    def __init__(self, n_embd, dropout, bias=True):\n","        super().__init__()\n","        self.c_fc    = nn.Linear(n_embd, 4 * n_embd, bias=bias)\n","        self.gelu    = nn.GELU() # nonlinear activation function\n","        self.c_proj  = nn.Linear(4 * n_embd, n_embd, bias=bias)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.c_fc(x)\n","        x = self.gelu(x)\n","        x = self.c_proj(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class Block(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout, block_size, bias=True):\n","        super().__init__()\n","        # LayerNorm and CausalSelfAttention with explicit parameters\n","        self.ln_1 = LayerNorm(n_embd, bias=bias)\n","        self.attn = CausalSelfAttention(n_embd, n_head, dropout, block_size, bias=bias)\n","        self.ln_2 = LayerNorm(n_embd, bias=bias)\n","        self.mlp = MLP(n_embd, dropout, bias=bias)  # MLP with explicit parameters\n","\n","    def forward(self, x):\n","        # Apply residual connection and pre-normalization\n","        x = x + self.attn(self.ln_1(x))  # Apply LayerNorm before attention\n","        x = x + self.mlp(self.ln_2(x))  # Apply LayerNorm before MLP\n","        return x\n","\n","\n","class GPT(nn.Module):\n","\n","    def __init__(self, vocab_size, block_size, n_embd, n_layer, n_head, dropout, bias=True):\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        super().__init__()\n","        assert vocab_size is not None\n","        assert block_size is not None\n","        self.vocab_size = vocab_size\n","        self.block_size = block_size\n","        self.n_embd = n_embd\n","        self.n_layer = n_layer\n","        self.n_head = n_head\n","        self.dropout = dropout\n","        self.bias = bias\n","\n","        self.transformer = nn.ModuleDict(dict(\n","            wte = nn.Embedding(vocab_size, n_embd), # token embeddings\n","            wpe = nn.Embedding(block_size, n_embd), # positional embeddings\n","            drop = nn.Dropout(dropout),\n","            h = nn.ModuleList([Block(n_embd, n_head, dropout, block_size, bias=bias) for _ in range(n_layer)]), # a stack of n_layer blocks\n","            ln_f = LayerNorm(n_embd, bias=bias), # final layer norm\n","        ))\n","        self.lm_head = nn.Linear(n_embd, vocab_size, bias=False) # projects the final transformer output to the vocab size\n","\n","        # init all weights\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        device = idx.device\n","        b, t = idx.size()\n","        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.cblock_size}\"\n","        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n","\n","        # forward the GPT model itself\n","        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n","        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n","        x = self.transformer.drop(tok_emb + pos_emb)\n","        for block in self.transformer.h:\n","            x = block(x)\n","        x = self.transformer.ln_f(x)\n","\n","        logits = self.lm_head(x)\n","\n","        loss = None\n","\n","        if targets is not None:\n","            # if we are given some desired targets also calculate the loss\n","            logits = self.lm_head(x)\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=13)\n","            # inference-time mini-optimization: only forward the lm_head on the very last position\n","            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n","            # loss = None\n","\n","        return logits, loss"],"metadata":{"id":"XVIg1aizaT7A","executionInfo":{"status":"ok","timestamp":1739759015995,"user_tz":300,"elapsed":290,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["eval_iters = 200\n","\n","@torch.no_grad()\n","def estimate_loss(phase, models):\n","    out = {}\n","    models.eval()\n","    for split in ['train', 'val']:\n","      losses = torch.zeros(eval_iters)\n","      for k in range(eval_iters):\n","          X, Y = get_batch(phase, mode=split)\n","          padding_mask_x = (X != padding_token_index).long()\n","          logits, loss = models(X, Y)\n","          losses[k] = loss.item()\n","      out[split] = losses.mean()\n","    models.train()\n","    return out"],"metadata":{"id":"cNC6DqTgcbZl","executionInfo":{"status":"ok","timestamp":1739762019804,"user_tz":300,"elapsed":298,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["# batch_size = 32 # how many independent sequences will we process in parallel?\n","block_size = 35 # what is the maximum context length for predictions?\n","max_iters = 150000\n","# num_epochs = 100\n","eval_interval = 100\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 20\n","n_embd = 256\n","n_head = 4\n","n_layer = 8\n","dropout = 0.0\n","# # torch.manual_seed(1337)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed_all(1337)\n","bias = True # if using bias inside all Linear layers\n","vocab_size = len(vocab)"],"metadata":{"id":"xOdwJ26Ax2e6","executionInfo":{"status":"ok","timestamp":1739759022221,"user_tz":300,"elapsed":2,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["wandb.init(project=\"transformer\", config={\n","    \"learning_rate\": 1e-5,\n","    \"batch_size\": 32,\n","    \"block_size\": 35,\n","    \"optimizer\": \"AdamW\",\n","    \"n_embd\": 256,\n","    \"n_head\": 4,\n","    \"n_layer\": 8,\n","    \"dropout\": 0.0,\n","})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"JG9utTPZvaU-","executionInfo":{"status":"ok","timestamp":1739762028336,"user_tz":300,"elapsed":3646,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"4e89f597-e0ab-4a63-cf4b-31bfd350378b"},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250217_031344-t1tzjxu9</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9' target=\"_blank\">glorious-rain-13</a></strong> to <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a072a9098d0>"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["def accuracy(model):\n","    correct = 0\n","    for j in range(100):\n","\n","        a = np.random.choice(np.arange(1000000), 1)\n","        b = np.random.choice(np.arange(1000000), 1)\n","\n","        c = a + b\n","        input = f\"{a.item()}+{b.item()}=\"\n","        context = torch.tensor(encode(input), dtype=torch.long, device=device)\n","        output = generate(model, context, 100, 1)\n","        if output == f\"{a.item()}+{b.item()}={c.item()}\":\n","            correct += 1\n","    print(f\"Accuracy for addition: {correct / 100} \")\n","    return correct / 100"],"metadata":{"id":"eMP3xYrvpdoW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate(model, idx, max_new_tokens, temperature=1.0, top_k=None):\n","    \"\"\"\n","    Generate a sequence of tokens given an initial sequence.\n","\n","    Parameters:\n","        model (nn.Module): The model used for generation.\n","        idx (torch.Tensor or list): Initial sequence of indices (LongTensor of shape (b,t)).\n","        max_new_tokens (int): Number of new tokens to generate.\n","        temperature (float): Scaling factor for logits before softmax.\n","        top_k (int, optional): If specified, restricts sampling to top k tokens.\n","\n","    Returns:\n","        torch.Tensor: The generated sequence.\n","    \"\"\"\n","    idx = idx.unsqueeze(0) if idx.dim() == 1 else idx\n","    idx = torch.tensor(idx, device=model.device) if not isinstance(idx, torch.Tensor) else idx.to(model.device)\n","\n","    for _ in range(max_new_tokens):\n","        # Ensure context length does not exceed model's block size\n","        idx_cond = idx if idx.size(1) <= model.block_size else idx[:, -model.block_size:]\n","\n","        # Forward pass to get logits\n","        logits, _ = model(idx_cond)\n","\n","        # Extract logits for the last token and apply temperature scaling\n","        logits = logits[:, -1, :] / temperature\n","\n","        # Apply top-k filtering if necessary\n","        if top_k is not None:\n","            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n","            logits[logits < v[:, [-1]]] = -float('Inf')\n","\n","        # Convert logits to probabilities\n","        probs = F.softmax(logits, dim=-1)\n","\n","        # Sample next token\n","        idx_next = torch.multinomial(probs, num_samples=1)\n","\n","        if idx_next == end_token_index:\n","            break\n","        # Append sampled token to sequence\n","\n","        # Append sampled token to sequence\n","        idx = torch.cat((idx, idx_next), dim=1)\n","\n","    return decode(idx.tolist()[0])\n"],"metadata":{"id":"sEKyA9IlOe5l","executionInfo":{"status":"ok","timestamp":1739762029185,"user_tz":300,"elapsed":297,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["model = GPT(vocab_size, block_size, n_embd, n_layer, n_head, dropout, bias=bias)\n","m = model.to(device)"],"metadata":{"id":"DPl7iF7e2D-n","executionInfo":{"status":"ok","timestamp":1739759028146,"user_tz":300,"elapsed":794,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"],"metadata":{"id":"snZoFt8qe76q","executionInfo":{"status":"ok","timestamp":1739759029955,"user_tz":300,"elapsed":548,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# print the number of parameters in the model\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","phase = 1\n","best_acc = 0\n","counter = 0\n","best_loss = float('inf')\n","val_loss_list = []\n","acc_list = []\n","\n","patience = 50\n","\n","for iter in tqdm(range(max_iters), desc=\"Training Progress\"):\n","    if iter > 2000:\n","      phase = 2\n","    if iter > 4000:\n","      phase = 3\n","    if iter > 6000:\n","      phase = 4\n","    if iter > 8000:\n","      phase = 5\n","    if iter > 10000:\n","      phase = 6\n","    if iter > 12000:\n","      phase = \"mix\"\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % eval_interval == 0 or iter == max_iters - 1:\n","        losses = estimate_loss(phase, model)\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","        log_dict = {\"Loss\": losses['val']}\n","        val_loss_list.append(round(losses['val'].item(), 4))\n","\n","        if phase == \"mix\":\n","            # acc = accuracy(model)\n","\n","            # acc_list.append(acc)\n","            # log_dict[\"Accuracy\"] = acc\n","\n","            if losses['val'] < best_loss:\n","                counter = 0\n","                # best_acc = max(best_acc, acc)\n","                best_loss = min(best_loss, losses['val'])\n","            else:\n","                counter += 1\n","                if counter >= patience:\n","                    print(f\"Early Stopping at iteration {iter}\")\n","                    break\n","\n","        # record to W&B\n","        wandb.log(log_dict)\n","\n","    # sample a batch of data\n","\n","    xb, yb = get_batch(phase)\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n"],"metadata":{"id":"odtqfBE0swtz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739763040520,"user_tz":300,"elapsed":1004888,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"8f1e8645-04f0-4ce6-810f-b1ddaccec852"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["6.33472 M parameters\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 7/150000 [00:02<11:13:57,  3.71it/s] "]},{"output_type":"stream","name":"stdout","text":["step 0: train loss 1.2019, val loss 1.2037\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 109/150000 [00:06<4:04:40, 10.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 100: train loss 0.3390, val loss 0.3400\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 211/150000 [00:10<4:04:48, 10.20it/s]"]},{"output_type":"stream","name":"stdout","text":["step 200: train loss 0.3362, val loss 0.3373\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 307/150000 [00:14<4:05:30, 10.16it/s]"]},{"output_type":"stream","name":"stdout","text":["step 300: train loss 0.3367, val loss 0.3365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 409/150000 [00:18<4:05:14, 10.17it/s]"]},{"output_type":"stream","name":"stdout","text":["step 400: train loss 0.3368, val loss 0.3362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 511/150000 [00:22<4:06:04, 10.13it/s]"]},{"output_type":"stream","name":"stdout","text":["step 500: train loss 0.3367, val loss 0.3364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 607/150000 [00:26<4:07:37, 10.06it/s]"]},{"output_type":"stream","name":"stdout","text":["step 600: train loss 0.3362, val loss 0.3364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   0%|          | 709/150000 [00:30<4:07:28, 10.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 700: train loss 0.3369, val loss 0.3365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 811/150000 [00:35<4:06:17, 10.10it/s]"]},{"output_type":"stream","name":"stdout","text":["step 800: train loss 0.3360, val loss 0.3353\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 907/150000 [00:39<4:07:10, 10.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 900: train loss 0.3357, val loss 0.3363\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1009/150000 [00:43<4:06:25, 10.08it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1000: train loss 0.3355, val loss 0.3364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1111/150000 [00:47<4:06:32, 10.06it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1100: train loss 0.3379, val loss 0.3370\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1207/150000 [00:51<4:07:42, 10.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1200: train loss 0.3358, val loss 0.3356\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1309/150000 [00:55<4:07:03, 10.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1300: train loss 0.3362, val loss 0.3362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1411/150000 [00:59<4:07:56,  9.99it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1400: train loss 0.3368, val loss 0.3376\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1507/150000 [01:03<4:07:31, 10.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1500: train loss 0.3357, val loss 0.3358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1609/150000 [01:07<4:07:41,  9.99it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1600: train loss 0.3360, val loss 0.3358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1711/150000 [01:11<4:07:54,  9.97it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1700: train loss 0.3360, val loss 0.3359\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|          | 1807/150000 [01:15<4:08:03,  9.96it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1800: train loss 0.3353, val loss 0.3357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|▏         | 1909/150000 [01:20<4:08:00,  9.95it/s]"]},{"output_type":"stream","name":"stdout","text":["step 1900: train loss 0.3364, val loss 0.3360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|▏         | 2011/150000 [01:24<4:09:32,  9.88it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2000: train loss 0.3364, val loss 0.3362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|▏         | 2107/150000 [01:28<4:08:38,  9.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2100: train loss 0.7165, val loss 0.7162\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   1%|▏         | 2209/150000 [01:32<4:08:55,  9.90it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2200: train loss 0.7120, val loss 0.7109\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2311/150000 [01:36<4:09:26,  9.87it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2300: train loss 0.7105, val loss 0.7114\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2407/150000 [01:40<4:09:46,  9.85it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2400: train loss 0.7109, val loss 0.7109\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2509/150000 [01:45<4:08:33,  9.89it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2500: train loss 0.7092, val loss 0.7102\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2611/150000 [01:49<4:08:52,  9.87it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2600: train loss 0.7106, val loss 0.7107\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2707/150000 [01:53<4:09:00,  9.86it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2700: train loss 0.7106, val loss 0.7108\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2809/150000 [01:57<4:10:07,  9.81it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2800: train loss 0.7103, val loss 0.7101\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 2911/150000 [02:01<4:08:58,  9.85it/s]"]},{"output_type":"stream","name":"stdout","text":["step 2900: train loss 0.7116, val loss 0.7121\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3007/150000 [02:05<4:09:25,  9.82it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3000: train loss 0.7104, val loss 0.7106\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3109/150000 [02:10<4:09:59,  9.79it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3100: train loss 0.7092, val loss 0.7101\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3211/150000 [02:14<4:09:31,  9.80it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3200: train loss 0.7127, val loss 0.7119\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3307/150000 [02:18<4:10:37,  9.75it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3300: train loss 0.7107, val loss 0.7105\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3409/150000 [02:22<4:10:41,  9.75it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3400: train loss 0.7104, val loss 0.7108\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3511/150000 [02:27<4:09:44,  9.78it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3500: train loss 0.7106, val loss 0.7105\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3607/150000 [02:31<4:10:09,  9.75it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3600: train loss 0.7103, val loss 0.7101\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   2%|▏         | 3709/150000 [02:35<4:10:26,  9.74it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3700: train loss 0.7101, val loss 0.7099\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 3811/150000 [02:39<4:09:29,  9.77it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3800: train loss 0.7095, val loss 0.7092\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 3907/150000 [02:43<4:10:19,  9.73it/s]"]},{"output_type":"stream","name":"stdout","text":["step 3900: train loss 0.7105, val loss 0.7093\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4009/150000 [02:48<4:09:54,  9.74it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4000: train loss 0.7103, val loss 0.7097\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4111/150000 [02:52<4:10:09,  9.72it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4100: train loss 0.9094, val loss 0.9091\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4207/150000 [02:56<4:10:44,  9.69it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4200: train loss 0.9072, val loss 0.9067\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4309/150000 [03:00<4:09:35,  9.73it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4300: train loss 0.9070, val loss 0.9066\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4411/150000 [03:05<4:09:45,  9.72it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4400: train loss 0.9061, val loss 0.9062\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4507/150000 [03:09<4:10:39,  9.67it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4500: train loss 0.9072, val loss 0.9071\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4609/150000 [03:13<4:09:42,  9.70it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4600: train loss 0.9069, val loss 0.9068\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4711/150000 [03:17<4:10:10,  9.68it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4700: train loss 0.9066, val loss 0.9072\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4807/150000 [03:21<4:09:54,  9.68it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4800: train loss 0.9066, val loss 0.9060\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 4909/150000 [03:26<4:09:26,  9.69it/s]"]},{"output_type":"stream","name":"stdout","text":["step 4900: train loss 0.9065, val loss 0.9060\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 5011/150000 [03:30<4:09:18,  9.69it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5000: train loss 0.9059, val loss 0.9056\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 5107/150000 [03:34<4:09:59,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5100: train loss 0.9072, val loss 0.9063\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   3%|▎         | 5209/150000 [03:38<4:09:31,  9.67it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5200: train loss 0.9067, val loss 0.9062\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▎         | 5311/150000 [03:43<4:09:09,  9.68it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5300: train loss 0.9061, val loss 0.9067\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▎         | 5407/150000 [03:47<4:09:41,  9.65it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5400: train loss 0.9067, val loss 0.9062\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▎         | 5509/150000 [03:51<4:09:22,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5500: train loss 0.9056, val loss 0.9060\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▎         | 5611/150000 [03:56<4:10:02,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5600: train loss 0.9062, val loss 0.9058\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 5707/150000 [04:00<4:08:56,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5700: train loss 0.9066, val loss 0.9060\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 5809/150000 [04:04<4:08:49,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5800: train loss 0.9060, val loss 0.9067\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 5911/150000 [04:08<4:10:15,  9.60it/s]"]},{"output_type":"stream","name":"stdout","text":["step 5900: train loss 0.9056, val loss 0.9062\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6007/150000 [04:12<4:08:32,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6000: train loss 0.9069, val loss 0.9066\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6109/150000 [04:17<4:09:30,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6100: train loss 1.0328, val loss 1.0331\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6211/150000 [04:21<4:09:10,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6200: train loss 1.0285, val loss 1.0280\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6307/150000 [04:25<4:09:04,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6300: train loss 1.0275, val loss 1.0275\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6409/150000 [04:30<4:08:31,  9.63it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6400: train loss 1.0271, val loss 1.0273\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6511/150000 [04:34<4:08:23,  9.63it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6500: train loss 1.0270, val loss 1.0274\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6607/150000 [04:38<4:08:39,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6600: train loss 1.0278, val loss 1.0276\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   4%|▍         | 6709/150000 [04:42<4:08:29,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6700: train loss 1.0273, val loss 1.0272\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 6811/150000 [04:47<4:07:57,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6800: train loss 1.0273, val loss 1.0277\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 6907/150000 [04:51<4:08:11,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 6900: train loss 1.0274, val loss 1.0275\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 7009/150000 [04:55<4:08:31,  9.59it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7000: train loss 1.0275, val loss 1.0276\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 7111/150000 [05:00<4:07:41,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7100: train loss 1.0278, val loss 1.0268\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 7207/150000 [05:04<4:07:46,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7200: train loss 1.0276, val loss 1.0269\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 7309/150000 [05:08<4:07:14,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7300: train loss 1.0267, val loss 1.0270\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▍         | 7411/150000 [05:12<4:06:54,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7400: train loss 1.0268, val loss 1.0271\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 7507/150000 [05:17<4:08:02,  9.57it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7500: train loss 1.0272, val loss 1.0272\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 7609/150000 [05:21<4:06:48,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7600: train loss 1.0282, val loss 1.0273\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 7711/150000 [05:25<4:06:33,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7700: train loss 1.0273, val loss 1.0270\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 7807/150000 [05:30<4:07:46,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7800: train loss 1.0270, val loss 1.0272\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 7909/150000 [05:34<4:06:07,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["step 7900: train loss 1.0273, val loss 1.0272\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 8011/150000 [05:38<4:05:46,  9.63it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8000: train loss 1.0267, val loss 1.0266\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 8107/150000 [05:42<4:07:59,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8100: train loss 1.1119, val loss 1.1119\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   5%|▌         | 8209/150000 [05:47<4:06:21,  9.59it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8200: train loss 1.1098, val loss 1.1107\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8311/150000 [05:51<4:06:35,  9.58it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8300: train loss 1.1099, val loss 1.1092\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8407/150000 [05:55<4:07:16,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8400: train loss 1.1089, val loss 1.1101\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8509/150000 [06:00<4:06:32,  9.57it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8500: train loss 1.1099, val loss 1.1094\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8611/150000 [06:04<4:07:17,  9.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8600: train loss 1.1098, val loss 1.1099\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8707/150000 [06:08<4:07:28,  9.52it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8700: train loss 1.1092, val loss 1.1099\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8809/150000 [06:13<4:06:48,  9.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8800: train loss 1.1096, val loss 1.1098\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 8905/150000 [06:17<5:35:52,  7.00it/s]"]},{"output_type":"stream","name":"stdout","text":["step 8900: train loss 1.1094, val loss 1.1095\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 9007/150000 [06:21<4:07:21,  9.50it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9000: train loss 1.1092, val loss 1.1092\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 9109/150000 [06:26<4:07:30,  9.49it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9100: train loss 1.1093, val loss 1.1090\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 9205/150000 [06:30<5:33:39,  7.03it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9200: train loss 1.1091, val loss 1.1097\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▌         | 9307/150000 [06:34<4:06:42,  9.50it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9300: train loss 1.1089, val loss 1.1091\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▋         | 9409/150000 [06:39<4:06:15,  9.52it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9400: train loss 1.1085, val loss 1.1091\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▋         | 9505/150000 [06:43<5:32:06,  7.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9500: train loss 1.1086, val loss 1.1091\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▋         | 9607/150000 [06:47<4:05:14,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9600: train loss 1.1094, val loss 1.1081\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   6%|▋         | 9709/150000 [06:52<4:05:20,  9.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9700: train loss 1.1089, val loss 1.1090\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 9805/150000 [06:56<5:29:57,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9800: train loss 1.1081, val loss 1.1086\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 9907/150000 [07:00<4:04:28,  9.55it/s]"]},{"output_type":"stream","name":"stdout","text":["step 9900: train loss 1.1093, val loss 1.1089\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10009/150000 [07:04<4:04:11,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10000: train loss 1.1089, val loss 1.1091\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10105/150000 [07:09<5:29:12,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10100: train loss 1.1700, val loss 1.1694\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10207/150000 [07:13<4:03:33,  9.57it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10200: train loss 1.1691, val loss 1.1689\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10309/150000 [07:17<4:03:31,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10300: train loss 1.1682, val loss 1.1689\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10411/150000 [07:22<4:03:09,  9.57it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10400: train loss 1.1688, val loss 1.1686\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10507/150000 [07:26<4:03:49,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10500: train loss 1.1686, val loss 1.1690\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10609/150000 [07:30<4:02:57,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10600: train loss 1.1685, val loss 1.1687\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10705/150000 [07:35<5:28:40,  7.06it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10700: train loss 1.1677, val loss 1.1687\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10807/150000 [07:39<4:04:01,  9.51it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10800: train loss 1.1684, val loss 1.1684\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 10909/150000 [07:43<4:02:42,  9.55it/s]"]},{"output_type":"stream","name":"stdout","text":["step 10900: train loss 1.1684, val loss 1.1683\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 11005/150000 [07:48<5:28:27,  7.05it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11000: train loss 1.1684, val loss 1.1687\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 11107/150000 [07:52<4:02:35,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11100: train loss 1.1678, val loss 1.1682\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   7%|▋         | 11209/150000 [07:56<4:02:21,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11200: train loss 1.1686, val loss 1.1682\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11305/150000 [08:00<5:28:27,  7.04it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11300: train loss 1.1681, val loss 1.1676\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11407/150000 [08:05<4:02:16,  9.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11400: train loss 1.1684, val loss 1.1684\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11509/150000 [08:09<4:02:28,  9.52it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11500: train loss 1.1682, val loss 1.1685\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11605/150000 [08:13<5:29:14,  7.01it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11600: train loss 1.1678, val loss 1.1687\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11707/150000 [08:18<4:01:43,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11700: train loss 1.1687, val loss 1.1682\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11809/150000 [08:22<4:01:37,  9.53it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11800: train loss 1.1686, val loss 1.1686\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 11905/150000 [08:26<5:25:40,  7.07it/s]"]},{"output_type":"stream","name":"stdout","text":["step 11900: train loss 1.1685, val loss 1.1672\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12007/150000 [08:31<4:00:58,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12000: train loss 1.1680, val loss 1.1677\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12109/150000 [08:35<4:05:38,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12100: train loss 1.2460, val loss 1.2472\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12205/150000 [08:39<5:31:05,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12200: train loss 1.2409, val loss 1.2410\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12307/150000 [08:44<4:04:30,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12300: train loss 1.2376, val loss 1.2386\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12409/150000 [08:48<4:06:08,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12400: train loss 1.2366, val loss 1.2372\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12511/150000 [08:53<4:04:41,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12500: train loss 1.2360, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12607/150000 [08:57<4:03:42,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12600: train loss 1.2362, val loss 1.2376\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   8%|▊         | 12709/150000 [09:01<4:04:22,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12700: train loss 1.2374, val loss 1.2382\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▊         | 12811/150000 [09:06<4:03:16,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12800: train loss 1.2364, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▊         | 12907/150000 [09:10<4:03:39,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 12900: train loss 1.2352, val loss 1.2358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▊         | 13009/150000 [09:14<4:03:47,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13000: train loss 1.2339, val loss 1.2366\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▊         | 13105/150000 [09:19<5:29:07,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13100: train loss 1.2367, val loss 1.2366\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13207/150000 [09:23<4:04:12,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13200: train loss 1.2377, val loss 1.2382\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13309/150000 [09:28<4:02:54,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13300: train loss 1.2388, val loss 1.2395\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13405/150000 [09:32<5:28:16,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13400: train loss 1.2514, val loss 1.2512\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13507/150000 [09:36<4:03:07,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13500: train loss 1.2384, val loss 1.2380\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13609/150000 [09:41<4:01:42,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13600: train loss 1.2360, val loss 1.2369\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13705/150000 [09:45<5:28:54,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13700: train loss 1.2362, val loss 1.2350\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13807/150000 [09:49<4:02:49,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13800: train loss 1.2362, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 13909/150000 [09:54<4:01:13,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 13900: train loss 1.2357, val loss 1.2360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 14005/150000 [09:58<5:29:40,  6.88it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14000: train loss 1.2352, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 14107/150000 [10:02<4:01:18,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14100: train loss 1.2364, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:   9%|▉         | 14209/150000 [10:07<4:00:24,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14200: train loss 1.2360, val loss 1.2353\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14311/150000 [10:11<4:02:45,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14300: train loss 1.2357, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14407/150000 [10:16<4:00:16,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14400: train loss 1.2361, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14509/150000 [10:20<4:01:30,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14500: train loss 1.2377, val loss 1.2396\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14605/150000 [10:24<5:25:17,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14600: train loss 1.2414, val loss 1.2401\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14707/150000 [10:29<3:59:41,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14700: train loss 1.2369, val loss 1.2382\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14809/150000 [10:33<4:01:10,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14800: train loss 1.2384, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|▉         | 14911/150000 [10:37<3:59:17,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 14900: train loss 1.2375, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15007/150000 [10:42<3:59:58,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15000: train loss 1.2353, val loss 1.2353\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15109/150000 [10:46<4:01:19,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15100: train loss 1.2366, val loss 1.2348\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15205/150000 [10:50<5:25:13,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15200: train loss 1.2362, val loss 1.2367\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15307/150000 [10:55<3:59:36,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15300: train loss 1.2356, val loss 1.2370\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15409/150000 [10:59<3:58:35,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15400: train loss 1.2362, val loss 1.2360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15505/150000 [11:03<5:23:30,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15500: train loss 1.2362, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15607/150000 [11:08<3:59:56,  9.33it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15600: train loss 1.2373, val loss 1.2376\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  10%|█         | 15709/150000 [11:12<3:59:16,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15700: train loss 1.2359, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 15805/150000 [11:17<5:22:54,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15800: train loss 1.2386, val loss 1.2398\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 15907/150000 [11:21<3:58:45,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 15900: train loss 1.2377, val loss 1.2372\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16009/150000 [11:25<3:57:41,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16000: train loss 1.2380, val loss 1.2391\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16105/150000 [11:30<5:22:00,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16100: train loss 1.2371, val loss 1.2372\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16207/150000 [11:34<3:57:19,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16200: train loss 1.2361, val loss 1.2363\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16309/150000 [11:38<3:56:49,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16300: train loss 1.2361, val loss 1.2356\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16405/150000 [11:43<5:23:04,  6.89it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16400: train loss 1.2357, val loss 1.2368\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16507/150000 [11:47<3:57:58,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16500: train loss 1.2348, val loss 1.2364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16609/150000 [11:52<3:57:11,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16600: train loss 1.2363, val loss 1.2355\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16705/150000 [11:56<5:24:32,  6.85it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16700: train loss 1.2348, val loss 1.2350\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█         | 16807/150000 [12:00<3:58:37,  9.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16800: train loss 1.2339, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█▏        | 16909/150000 [12:05<3:58:12,  9.31it/s]"]},{"output_type":"stream","name":"stdout","text":["step 16900: train loss 1.2353, val loss 1.2346\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█▏        | 17005/150000 [12:09<5:22:18,  6.88it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17000: train loss 1.2360, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█▏        | 17107/150000 [12:14<3:57:34,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17100: train loss 1.2364, val loss 1.2359\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  11%|█▏        | 17209/150000 [12:18<4:00:15,  9.21it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17200: train loss 1.2353, val loss 1.2346\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17305/150000 [12:22<5:20:14,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17300: train loss 1.2353, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17407/150000 [12:27<3:56:04,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17400: train loss 1.2352, val loss 1.2361\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17509/150000 [12:31<3:56:32,  9.33it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17500: train loss 1.2369, val loss 1.2348\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17605/150000 [12:35<5:19:22,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17600: train loss 1.2449, val loss 1.2440\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17707/150000 [12:40<3:55:26,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17700: train loss 1.2529, val loss 1.2514\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17809/150000 [12:44<3:54:57,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17800: train loss 1.2364, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 17905/150000 [12:49<5:17:23,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 17900: train loss 1.2353, val loss 1.2365\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18007/150000 [12:53<3:54:51,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18000: train loss 1.2351, val loss 1.2358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18109/150000 [12:57<3:54:18,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18100: train loss 1.2359, val loss 1.2361\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18205/150000 [13:02<5:16:20,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18200: train loss 1.2344, val loss 1.2346\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18307/150000 [13:06<3:55:28,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18300: train loss 1.2356, val loss 1.2343\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18409/150000 [13:10<3:53:24,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18400: train loss 1.2355, val loss 1.2359\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18505/150000 [13:15<5:15:51,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18500: train loss 1.2357, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18607/150000 [13:19<3:54:09,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18600: train loss 1.2371, val loss 1.2361\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  12%|█▏        | 18709/150000 [13:24<3:53:19,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18700: train loss 1.2359, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 18805/150000 [13:28<5:16:02,  6.92it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18800: train loss 1.2368, val loss 1.2366\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 18907/150000 [13:32<3:52:54,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 18900: train loss 1.2361, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19009/150000 [13:37<3:52:45,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19000: train loss 1.2373, val loss 1.2374\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19111/150000 [13:41<3:53:35,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19100: train loss 1.2365, val loss 1.2354\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19207/150000 [13:45<3:52:28,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19200: train loss 1.2346, val loss 1.2361\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19309/150000 [13:50<3:52:31,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19300: train loss 1.2355, val loss 1.2367\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19405/150000 [13:54<5:15:08,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19400: train loss 1.2453, val loss 1.2467\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19507/150000 [13:58<3:52:52,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19500: train loss 1.2373, val loss 1.2369\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19609/150000 [14:03<3:52:38,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19600: train loss 1.2370, val loss 1.2373\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19705/150000 [14:07<5:12:49,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19700: train loss 1.2357, val loss 1.2363\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19807/150000 [14:12<3:52:30,  9.33it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19800: train loss 1.2353, val loss 1.2358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 19909/150000 [14:16<3:52:05,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 19900: train loss 1.2365, val loss 1.2359\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 20011/150000 [14:20<3:50:53,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20000: train loss 1.2356, val loss 1.2360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 20107/150000 [14:25<3:50:27,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20100: train loss 1.2358, val loss 1.2364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  13%|█▎        | 20209/150000 [14:29<3:50:43,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20200: train loss 1.2356, val loss 1.2364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▎        | 20311/150000 [14:33<3:50:00,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20300: train loss 1.2350, val loss 1.2346\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▎        | 20407/150000 [14:38<3:50:05,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20400: train loss 1.2358, val loss 1.2358\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▎        | 20509/150000 [14:42<3:49:19,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20500: train loss 1.2356, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▎        | 20611/150000 [14:47<3:49:44,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20600: train loss 1.2364, val loss 1.2360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 20707/150000 [14:51<3:50:12,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20700: train loss 1.2380, val loss 1.2370\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 20809/150000 [14:55<3:49:49,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20800: train loss 1.2385, val loss 1.2371\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 20905/150000 [14:59<5:09:32,  6.95it/s]"]},{"output_type":"stream","name":"stdout","text":["step 20900: train loss 1.2390, val loss 1.2379\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21007/150000 [15:04<3:49:19,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21000: train loss 1.2371, val loss 1.2373\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21109/150000 [15:08<3:47:50,  9.43it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21100: train loss 1.2349, val loss 1.2368\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21211/150000 [15:13<3:48:20,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21200: train loss 1.2354, val loss 1.2349\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21307/150000 [15:17<3:48:56,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21300: train loss 1.2361, val loss 1.2355\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21409/150000 [15:21<3:48:47,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21400: train loss 1.2360, val loss 1.2356\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21505/150000 [15:26<5:09:55,  6.91it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21500: train loss 1.2345, val loss 1.2364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21607/150000 [15:30<3:48:08,  9.38it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21600: train loss 1.2350, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  14%|█▍        | 21709/150000 [15:34<3:47:43,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21700: train loss 1.2365, val loss 1.2369\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 21805/150000 [15:39<5:07:45,  6.94it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21800: train loss 1.2436, val loss 1.2420\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 21907/150000 [15:43<3:47:17,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 21900: train loss 1.2369, val loss 1.2380\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 22009/150000 [15:47<3:47:42,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22000: train loss 1.2380, val loss 1.2383\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 22111/150000 [15:52<3:47:27,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22100: train loss 1.2352, val loss 1.2353\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 22207/150000 [15:56<3:47:24,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22200: train loss 1.2363, val loss 1.2361\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 22309/150000 [16:01<3:48:45,  9.30it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22300: train loss 1.2362, val loss 1.2359\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▍        | 22405/150000 [16:05<5:07:10,  6.92it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22400: train loss 1.2359, val loss 1.2360\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 22507/150000 [16:09<3:46:58,  9.36it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22500: train loss 1.2363, val loss 1.2356\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 22609/150000 [16:14<3:46:59,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22600: train loss 1.2339, val loss 1.2357\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 22705/150000 [16:18<5:06:36,  6.92it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22700: train loss 1.2375, val loss 1.2369\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 22807/150000 [16:22<3:46:50,  9.35it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22800: train loss 1.2351, val loss 1.2362\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 22909/150000 [16:27<3:45:37,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["step 22900: train loss 1.2370, val loss 1.2383\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 23011/150000 [16:31<3:44:55,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["step 23000: train loss 1.2393, val loss 1.2412\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 23107/150000 [16:36<3:46:29,  9.34it/s]"]},{"output_type":"stream","name":"stdout","text":["step 23100: train loss 1.2370, val loss 1.2364\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  15%|█▌        | 23209/150000 [16:40<3:44:55,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["step 23200: train loss 1.2355, val loss 1.2348\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress:  16%|█▌        | 23300/150000 [16:44<1:31:02, 23.19it/s]"]},{"output_type":"stream","name":"stdout","text":["step 23300: train loss 1.2363, val loss 1.2360\n","Early Stopping at iteration 23300\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"UzlPUoW3k1zY","executionInfo":{"status":"ok","timestamp":1739763055343,"user_tz":300,"elapsed":2457,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"2b43f67d-89da-4394-c2d5-8d6262988406"},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▁▁▁▁▁▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.23479</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">glorious-rain-13</strong> at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/t1tzjxu9</a><br> View project at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250217_031344-t1tzjxu9/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["fig = go.Figure()\n","\n","iterations = list(range(58))\n","\n","# Add lines\n","fig.add_trace(go.Scatter(x=iterations, y=val_loss_list, mode='lines+markers', name='Validation Loss'))\n","fig.add_trace(go.Scatter(x=iterations, y=acc_test_list, mode='lines+markers', name='Test Accuracy'))\n","fig.add_trace(go.Scatter(x=iterations, y=acc_all_list, mode='lines+markers', name='All Accuracy'))\n","\n","# Set title label\n","fig.update_layout(\n","    title=\"Validation Loss & Accuracy over Iterations\",\n","    xaxis_title=\"Iterations\",\n","    yaxis_title=\"Metrics\",\n","    legend_title=\"Metrics\",\n","    width = 900,\n","    height = 500\n",")\n","\n","fig.show()\n","\n","wandb.init(project=\"transformer\", name=\"val_loss and accuracy plot\")\n","wandb.log({\"Interactive Chart\": wandb.Html(fig.to_html())})\n","wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":673},"id":"m4yP9is176im","executionInfo":{"status":"ok","timestamp":1739394233958,"user_tz":300,"elapsed":8115,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"f8b0fb0e-3102-4198-9487-c100b4cdc770"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"98d18861-8972-4170-aaef-e5daa4afb775\" class=\"plotly-graph-div\" style=\"height:500px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"98d18861-8972-4170-aaef-e5daa4afb775\")) {                    Plotly.newPlot(                        \"98d18861-8972-4170-aaef-e5daa4afb775\",                        [{\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57],\"y\":[1.5728,1.4822,1.4341,1.384,1.2915,1.2442,1.2058,1.186,1.2064,1.1802,1.1875,1.1776,1.1773,1.1668,1.184,1.1691,1.1737,1.16,1.1573,1.1618,1.1669,1.1611,1.1525,1.1484,1.1418,1.149,1.149,1.1539,1.1423,1.1488,1.1385,1.1358,1.1492,1.1364,1.1439,1.1298,1.1268,1.1155,1.0992,1.0971,1.0909,1.1008,1.111,1.071,1.0844,1.092,1.0714,1.0848,1.0855,1.0902,1.075,1.0825,1.0894,1.0827,1.0783,1.0963,1.0939,1.0825],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Test Accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57],\"y\":[0.01,0.01,0.04,0.01,0.07,0.19,0.23,0.17,0.21,0.22,0.27,0.25,0.29,0.35,0.26,0.38,0.31,0.35,0.32,0.32,0.45,0.33,0.54,0.43,0.39,0.36,0.35,0.36,0.41,0.39,0.46,0.46,0.5,0.37,0.46,0.53,0.44,0.5,0.49,0.46,0.62,0.58,0.66,0.62,0.75,0.61,0.69,0.69,0.71,0.69,0.66,0.69,0.75,0.63,0.67,0.78,0.77,0.71],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"All Accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57],\"y\":[0.01,0.01,0.0,0.03,0.12,0.14,0.28,0.31,0.31,0.27,0.26,0.16,0.34,0.3,0.31,0.37,0.31,0.36,0.31,0.43,0.35,0.25,0.38,0.42,0.39,0.48,0.39,0.53,0.41,0.39,0.54,0.45,0.55,0.52,0.51,0.53,0.56,0.58,0.6,0.63,0.55,0.63,0.69,0.76,0.74,0.67,0.76,0.69,0.76,0.71,0.72,0.65,0.75,0.78,0.73,0.77,0.86,0.69],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Validation Loss & Accuracy over Iterations\"},\"xaxis\":{\"title\":{\"text\":\"Iterations\"}},\"yaxis\":{\"title\":{\"text\":\"Metrics\"}},\"legend\":{\"title\":{\"text\":\"Metrics\"}},\"width\":900,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('98d18861-8972-4170-aaef-e5daa4afb775');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250212_210345-osjbemcx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/osjbemcx' target=\"_blank\">val_loss and accuracy plot</a></strong> to <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/osjbemcx' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/osjbemcx</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">val_loss and accuracy plot</strong> at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/osjbemcx' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/osjbemcx</a><br> View project at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250212_210345-osjbemcx/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["def accuracy_print(model, num_digits, need_print=False):\n","        correct = 0\n","\n","        for j in range(100):\n","            a = np.random.choice(np.arange(10**num_digits), 1)\n","            b = np.random.choice(np.arange(10**num_digits), 1)\n","            c = a + b\n","            reversed_c = np.array([str(x)[::-1] for x in c])\n","            input = f\"{a.item()}+{b.item()}=\"\n","            context = torch.tensor(encode(input), dtype=torch.long, device=device)\n","            output = generate(model, context, 100, 1)\n","            if need_print:\n","                print(f\"Input: {input}\")\n","                print(f\"Output: {output}\")\n","                print(f\"Expected: {a.item()}+{b.item()}={reversed_c.item()}\")\n","                print(\"-----------\")\n","            if output == f\"{a.item()}+{b.item()}={reversed_c.item()}\":\n","                correct += 1\n","        acc = correct / 100\n","        print(f\"Accuracy for {num_digits} digits addition: {acc} \")\n","        return acc"],"metadata":{"id":"Gf-KW9gJiu6g","executionInfo":{"status":"ok","timestamp":1739761714788,"user_tz":300,"elapsed":1059,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["accuracy_print(model, 1, need_print=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJBWmy5C4xIV","executionInfo":{"status":"ok","timestamp":1739761717758,"user_tz":300,"elapsed":1334,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"1945681a-213f-4ff4-fb47-05e4885602fd"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 6+2=\n","Output: 6+2=8\n","Expected: 6+2=8\n","-----------\n","Input: 9+3=\n","Output: 9+3=21\n","Expected: 9+3=21\n","-----------\n","Input: 5+3=\n","Output: 5+3=8\n","Expected: 5+3=8\n","-----------\n","Input: 7+8=\n","Output: 7+8=51\n","Expected: 7+8=51\n","-----------\n","Input: 0+6=\n","Output: 0+6=6\n","Expected: 0+6=6\n","-----------\n","Input: 5+8=\n","Output: 5+8=31\n","Expected: 5+8=31\n","-----------\n","Input: 0+1=\n","Output: 0+1=1\n","Expected: 0+1=1\n","-----------\n","Input: 6+4=\n","Output: 6+4=01\n","Expected: 6+4=01\n","-----------\n","Input: 2+1=\n","Output: 2+1=3\n","Expected: 2+1=3\n","-----------\n","Input: 5+6=\n","Output: 5+6=11\n","Expected: 5+6=11\n","-----------\n","Input: 7+9=\n","Output: 7+9=61\n","Expected: 7+9=61\n","-----------\n","Input: 5+9=\n","Output: 5+9=41\n","Expected: 5+9=41\n","-----------\n","Input: 4+9=\n","Output: 4+9=31\n","Expected: 4+9=31\n","-----------\n","Input: 5+6=\n","Output: 5+6=11\n","Expected: 5+6=11\n","-----------\n","Input: 0+4=\n","Output: 0+4=4\n","Expected: 0+4=4\n","-----------\n","Input: 5+5=\n","Output: 5+5=01\n","Expected: 5+5=01\n","-----------\n","Input: 0+3=\n","Output: 0+3=3\n","Expected: 0+3=3\n","-----------\n","Input: 5+4=\n","Output: 5+4=9\n","Expected: 5+4=9\n","-----------\n","Input: 0+2=\n","Output: 0+2=2\n","Expected: 0+2=2\n","-----------\n","Input: 0+7=\n","Output: 0+7=7\n","Expected: 0+7=7\n","-----------\n","Input: 7+5=\n","Output: 7+5=21\n","Expected: 7+5=21\n","-----------\n","Input: 0+7=\n","Output: 0+7=7\n","Expected: 0+7=7\n","-----------\n","Input: 5+2=\n","Output: 5+2=7\n","Expected: 5+2=7\n","-----------\n","Input: 4+0=\n","Output: 4+0=4\n","Expected: 4+0=4\n","-----------\n","Input: 4+9=\n","Output: 4+9=31\n","Expected: 4+9=31\n","-----------\n","Input: 9+0=\n","Output: 9+0=99\n","Expected: 9+0=9\n","-----------\n","Input: 7+8=\n","Output: 7+8=51\n","Expected: 7+8=51\n","-----------\n","Input: 5+9=\n","Output: 5+9=41\n","Expected: 5+9=41\n","-----------\n","Input: 7+6=\n","Output: 7+6=31\n","Expected: 7+6=31\n","-----------\n","Input: 7+5=\n","Output: 7+5=21\n","Expected: 7+5=21\n","-----------\n","Input: 5+4=\n","Output: 5+4=9\n","Expected: 5+4=9\n","-----------\n","Input: 9+1=\n","Output: 9+1=01\n","Expected: 9+1=01\n","-----------\n","Input: 8+0=\n","Output: 8+0=8\n","Expected: 8+0=8\n","-----------\n","Input: 5+2=\n","Output: 5+2=7\n","Expected: 5+2=7\n","-----------\n","Input: 4+9=\n","Output: 4+9=31\n","Expected: 4+9=31\n","-----------\n","Input: 4+5=\n","Output: 4+5=9\n","Expected: 4+5=9\n","-----------\n","Input: 2+8=\n","Output: 2+8=01\n","Expected: 2+8=01\n","-----------\n","Input: 1+8=\n","Output: 1+8=9\n","Expected: 1+8=9\n","-----------\n","Input: 5+8=\n","Output: 5+8=31\n","Expected: 5+8=31\n","-----------\n","Input: 9+9=\n","Output: 9+9=81\n","Expected: 9+9=81\n","-----------\n","Input: 5+6=\n","Output: 5+6=11\n","Expected: 5+6=11\n","-----------\n","Input: 1+9=\n","Output: 1+9=01\n","Expected: 1+9=01\n","-----------\n","Input: 8+7=\n","Output: 8+7=51\n","Expected: 8+7=51\n","-----------\n","Input: 5+7=\n","Output: 5+7=21\n","Expected: 5+7=21\n","-----------\n","Input: 1+5=\n","Output: 1+5=6\n","Expected: 1+5=6\n","-----------\n","Input: 2+1=\n","Output: 2+1=3\n","Expected: 2+1=3\n","-----------\n","Input: 9+2=\n","Output: 9+2=11\n","Expected: 9+2=11\n","-----------\n","Input: 0+0=\n","Output: 0+0=01\n","Expected: 0+0=0\n","-----------\n","Input: 3+1=\n","Output: 3+1=4\n","Expected: 3+1=4\n","-----------\n","Input: 4+1=\n","Output: 4+1=5\n","Expected: 4+1=5\n","-----------\n","Input: 8+3=\n","Output: 8+3=11\n","Expected: 8+3=11\n","-----------\n","Input: 4+1=\n","Output: 4+1=5\n","Expected: 4+1=5\n","-----------\n","Input: 9+0=\n","Output: 9+0=99\n","Expected: 9+0=9\n","-----------\n","Input: 0+3=\n","Output: 0+3=3\n","Expected: 0+3=3\n","-----------\n","Input: 2+2=\n","Output: 2+2=4\n","Expected: 2+2=4\n","-----------\n","Input: 5+9=\n","Output: 5+9=41\n","Expected: 5+9=41\n","-----------\n","Input: 1+6=\n","Output: 1+6=7\n","Expected: 1+6=7\n","-----------\n","Input: 5+4=\n","Output: 5+4=9\n","Expected: 5+4=9\n","-----------\n","Input: 5+7=\n","Output: 5+7=21\n","Expected: 5+7=21\n","-----------\n","Input: 2+6=\n","Output: 2+6=8\n","Expected: 2+6=8\n","-----------\n","Input: 1+1=\n","Output: 1+1=2\n","Expected: 1+1=2\n","-----------\n","Input: 1+9=\n","Output: 1+9=01\n","Expected: 1+9=01\n","-----------\n","Input: 5+5=\n","Output: 5+5=01\n","Expected: 5+5=01\n","-----------\n","Input: 8+7=\n","Output: 8+7=51\n","Expected: 8+7=51\n","-----------\n","Input: 7+6=\n","Output: 7+6=31\n","Expected: 7+6=31\n","-----------\n","Input: 7+4=\n","Output: 7+4=11\n","Expected: 7+4=11\n","-----------\n","Input: 0+9=\n","Output: 0+9=9\n","Expected: 0+9=9\n","-----------\n","Input: 9+2=\n","Output: 9+2=11\n","Expected: 9+2=11\n","-----------\n","Input: 8+6=\n","Output: 8+6=41\n","Expected: 8+6=41\n","-----------\n","Input: 6+9=\n","Output: 6+9=51\n","Expected: 6+9=51\n","-----------\n","Input: 5+0=\n","Output: 5+0=5\n","Expected: 5+0=5\n","-----------\n","Input: 8+8=\n","Output: 8+8=61\n","Expected: 8+8=61\n","-----------\n","Input: 2+3=\n","Output: 2+3=5\n","Expected: 2+3=5\n","-----------\n","Input: 4+7=\n","Output: 4+7=11\n","Expected: 4+7=11\n","-----------\n","Input: 5+5=\n","Output: 5+5=01\n","Expected: 5+5=01\n","-----------\n","Input: 1+1=\n","Output: 1+1=2\n","Expected: 1+1=2\n","-----------\n","Input: 1+1=\n","Output: 1+1=2\n","Expected: 1+1=2\n","-----------\n","Input: 5+7=\n","Output: 5+7=21\n","Expected: 5+7=21\n","-----------\n","Input: 7+5=\n","Output: 7+5=21\n","Expected: 7+5=21\n","-----------\n","Input: 2+5=\n","Output: 2+5=7\n","Expected: 2+5=7\n","-----------\n","Input: 2+2=\n","Output: 2+2=4\n","Expected: 2+2=4\n","-----------\n","Input: 4+6=\n","Output: 4+6=01\n","Expected: 4+6=01\n","-----------\n","Input: 3+2=\n","Output: 3+2=5\n","Expected: 3+2=5\n","-----------\n","Input: 7+1=\n","Output: 7+1=8\n","Expected: 7+1=8\n","-----------\n","Input: 0+4=\n","Output: 0+4=4\n","Expected: 0+4=4\n","-----------\n","Input: 1+5=\n","Output: 1+5=6\n","Expected: 1+5=6\n","-----------\n","Input: 9+0=\n","Output: 9+0=99\n","Expected: 9+0=9\n","-----------\n","Input: 6+0=\n","Output: 6+0=66\n","Expected: 6+0=6\n","-----------\n","Input: 9+6=\n","Output: 9+6=51\n","Expected: 9+6=51\n","-----------\n","Input: 0+8=\n","Output: 0+8=8\n","Expected: 0+8=8\n","-----------\n","Input: 5+2=\n","Output: 5+2=7\n","Expected: 5+2=7\n","-----------\n","Input: 5+2=\n","Output: 5+2=7\n","Expected: 5+2=7\n","-----------\n","Input: 3+6=\n","Output: 3+6=9\n","Expected: 3+6=9\n","-----------\n","Input: 4+7=\n","Output: 4+7=11\n","Expected: 4+7=11\n","-----------\n","Input: 4+2=\n","Output: 4+2=6\n","Expected: 4+2=6\n","-----------\n","Input: 4+9=\n","Output: 4+9=31\n","Expected: 4+9=31\n","-----------\n","Input: 2+2=\n","Output: 2+2=4\n","Expected: 2+2=4\n","-----------\n","Input: 1+5=\n","Output: 1+5=6\n","Expected: 1+5=6\n","-----------\n","Input: 5+0=\n","Output: 5+0=5\n","Expected: 5+0=5\n","-----------\n","Input: 2+9=\n","Output: 2+9=11\n","Expected: 2+9=11\n","-----------\n","Accuracy for 1 digits addition: 0.95 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.95"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["accuracy_print(model, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19uycVG97nVM","executionInfo":{"status":"ok","timestamp":1739761724298,"user_tz":300,"elapsed":1520,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"7ebe29e1-0456-4a64-8a80-53471503c3c9"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 2 digits addition: 1.0 \n"]},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["accuracy_print(model, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fVnQ-8h7qd8","executionInfo":{"status":"ok","timestamp":1739761727988,"user_tz":300,"elapsed":1292,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"84b5f1f7-b583-4711-9932-ca0157433e87"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 3 digits addition: 1.0 \n"]},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["accuracy_print(model, 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtV-ojTO489M","executionInfo":{"status":"ok","timestamp":1739761731923,"user_tz":300,"elapsed":1639,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"0119f4d0-b513-4850-95d9-21b11ff78e65"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 4 digits addition: 0.99 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.99"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["accuracy_print(model, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKwmkwJi5AFX","executionInfo":{"status":"ok","timestamp":1739761735813,"user_tz":300,"elapsed":2361,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"3f3371a0-19de-4488-9526-9d26365b8d87"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 5 digits addition: 0.94 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.94"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["accuracy_print(model, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ibl4JWaX7xKk","executionInfo":{"status":"ok","timestamp":1739761740183,"user_tz":300,"elapsed":2065,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"e1d6ce8a-b9c8-480d-a5e5-2f3585b60653"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 6 digits addition: 0.8 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.8"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["accuracy_print(model, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wmv1Cv5TAwVH","executionInfo":{"status":"ok","timestamp":1739761747586,"user_tz":300,"elapsed":5212,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"6dc70b6a-bf99-4a78-f188-16d225ab251d"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 7 digits addition: 0.01 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.01"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["accuracy_print(model, 8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArciJAZgA7nH","executionInfo":{"status":"ok","timestamp":1739761789377,"user_tz":300,"elapsed":40079,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"1299d5ab-bc74-49b6-f4f9-1e5d727937ba"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 8 digits addition: 0.0 \n"]},{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["def get_avg_performance(model):\n","    dict_acc = {}\n","    for num_dig in range(1, 9):\n","        dict_acc[num_dig] = accuracy_print(model, num_dig, need_print=False)\n","    return dict_acc"],"metadata":{"id":"xl73ZzRj8dLN","executionInfo":{"status":"ok","timestamp":1739761793187,"user_tz":300,"elapsed":1008,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["avg_performance = get_avg_performance(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6zbg__39wSG","executionInfo":{"status":"ok","timestamp":1739763130669,"user_tz":300,"elapsed":56068,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"603c2abd-bbc0-4696-97e4-bfa1814a1667"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for 1 digits addition: 0.97 \n","Accuracy for 2 digits addition: 1.0 \n","Accuracy for 3 digits addition: 1.0 \n","Accuracy for 4 digits addition: 0.98 \n","Accuracy for 5 digits addition: 1.0 \n","Accuracy for 6 digits addition: 1.0 \n","Accuracy for 7 digits addition: 0.02 \n","Accuracy for 8 digits addition: 0.0 \n"]}]},{"cell_type":"code","source":["x_values = list(avg_performance.keys())\n","y_values = list(avg_performance.values())\n","\n","\n","fig = go.Figure(go.Bar(x=x_values, y=y_values, marker_color='MediumPurple'))\n","\n","\n","fig.update_layout(\n","    title=\"Accuracy for different digits addition Reverse Applied\",\n","    xaxis_title=\"Num Digits\",\n","    yaxis_title=\"Accuracy\",\n","    template=\"plotly_white\",\n","    width=800,\n","    height= 500\n",")\n","\n","\n","fig.show()\n","\n","wandb.init(project=\"transformer\", name=\"Accuracy for different digits addition plot Reverse Applied\")\n","wandb.log({\"Interactive Chart\": wandb.Html(fig.to_html())})\n","wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":673},"id":"slIi1d5D_eda","executionInfo":{"status":"ok","timestamp":1739763573494,"user_tz":300,"elapsed":8537,"user":{"displayName":"ZIFEI BAI","userId":"03045138665814544162"}},"outputId":"9cb919ee-6e42-4dd6-9533-0984affad2a3"},"execution_count":96,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b4f4d31c-9760-46c5-936b-a17f0096a332\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4f4d31c-9760-46c5-936b-a17f0096a332\")) {                    Plotly.newPlot(                        \"b4f4d31c-9760-46c5-936b-a17f0096a332\",                        [{\"marker\":{\"color\":\"MediumPurple\"},\"x\":[1,2,3,4,5,6,7,8],\"y\":[0.97,1.0,1.0,0.98,1.0,1.0,0.02,0.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy for different digits addition Reverse Applied\"},\"xaxis\":{\"title\":{\"text\":\"Num Digits\"}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"}},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b4f4d31c-9760-46c5-936b-a17f0096a332');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250217_033926-70thkw5b</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/70thkw5b' target=\"_blank\">Accuracy for different digits addition plot Reverse Applied</a></strong> to <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/70thkw5b' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/70thkw5b</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">Accuracy for different digits addition plot Reverse Applied</strong> at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/70thkw5b' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer/runs/70thkw5b</a><br> View project at: <a href='https://wandb.ai/birdyyybai-university-of-michigan/transformer' target=\"_blank\">https://wandb.ai/birdyyybai-university-of-michigan/transformer</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250217_033926-70thkw5b/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["import subprocess\n","\n","os.system('git config --global user.email \"zifeibai@umich.edu\"')\n","os.system('git config --global user.name \"ZifeiBai\"')\n","\n","# 2️⃣ **Use Google Drive to store GitHub Token**\n","GITHUB_TOKEN_PATH = \"/content/drive/MyDrive/URPS/github_token.txt\"\n","if os.path.exists(GITHUB_TOKEN_PATH):\n","    with open(GITHUB_TOKEN_PATH, \"r\") as f:\n","        os.environ[\"GITHUB_TOKEN\"] = f.read().strip()\n","else:\n","    print(\"❌ GitHub Token\")\n","    exit(1)\n","\n","# 3️⃣ **Set up GitHub remote repo**\n","GIT_PATH = \"/content/drive/MyDrive/URPS/Git\"\n","REPO_URL = f\"https://{os.environ['GITHUB_TOKEN']}@github.com/ZifeiBai/URPS.git\"\n","\n","if not os.path.exists(GIT_PATH):\n","    print(f\"📁 Creating directory: {GIT_PATH}\")\n","    os.makedirs(GIT_PATH)\n","\n","# 4️⃣ **If .git/ does not exsit， need to clone**\n","if not os.path.exists(os.path.join(GIT_PATH, \".git\")):\n","    print(\"❌ Git repository not found. Cloning...\")\n","    subprocess.run(f\"rm -rf {GIT_PATH}\", shell=True, check=True)\n","    subprocess.run(f\"git clone {REPO_URL} {GIT_PATH}\", shell=True, check=True)\n","\n","# 5️⃣ **Enter Git repo**\n","os.chdir(GIT_PATH)\n","print(\"📂 Changed working directory to:\", os.getcwd())\n","\n","\n","# 6️⃣ **Check Git status**\n","status_output = subprocess.run(\"git status\", shell=True, capture_output=True, text=True)\n","print(status_output.stdout)\n","\n","#  **Push to Git**\n","print(\"🚀 Adding files to Git...\")\n","subprocess.run(\"git add .\", shell=True, check=True)\n","\n","print(\"📝 Committing changes...\")\n","commit_output = subprocess.run('git commit -m \"Auto update from Google Colab 2.6\"', shell=True, capture_output=True, text=True)\n","print(commit_output.stdout)\n","\n","\n","\n","print(\"📤 Pushing to GitHub...\")\n","push_output = subprocess.run(\"git push origin main\", shell=True, capture_output=True, text=True)\n","if \"fatal\" in push_output.stderr or \"error:\" in push_output.stderr:\n","    print(\"❌ Real Git Push Error:\", push_output.stderr)\n","else:\n","    print(\"✅ Git Push Success!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23jaqlhaaOGQ","executionInfo":{"status":"ok","timestamp":1739413611157,"user_tz":300,"elapsed":18845,"user":{"displayName":"Zifei Bai","userId":"12413018286570323363"}},"outputId":"2b5c660d-025a-4e8e-9c3f-ca31daebdb6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["📂 Changed working directory to: /content/drive/MyDrive/URPS/Git\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\tmodified:   transformer.ipynb\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","\n","🚀 Adding files to Git...\n","📝 Committing changes...\n","[main 60bbc33] Auto update from Google Colab 2.6\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite transformer.ipynb (95%)\n","\n","📤 Pushing to GitHub...\n","✅ Git Push Success!\n"]}]}]}